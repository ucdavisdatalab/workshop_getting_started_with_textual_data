{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ecf5d1",
   "metadata": {},
   "source": [
    "Topic Modeling\n",
    "============\n",
    "\n",
    "\n",
    "\n",
    "```{admonition} Learning Objectives\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "+ Explain what a topic model is, what it represents, and how to use one to explore a corpus\n",
    "+ Build a topic model\n",
    "+ Appraise the validity of a topic model and fine tune it accordingly\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101066c",
   "metadata": {},
   "source": [
    "Preliminiaries\n",
    "----------------\n",
    "\n",
    "As before, we'll use a file manifest to keep things orderly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af14157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blurbs: 1500 \n",
      "Date range: 1958--2018 \n",
      "Genres: Fiction, Classics, Nonfiction, Childrenâ€™s Books, Teen & Young Adult, Poetry, Humor\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>PUB_DATE</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>FILE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Patricia Briggs</td>\n",
       "      <td>The Hob's Bargain</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>2001-03-01</td>\n",
       "      <td>9780441008131</td>\n",
       "      <td>0174.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>DK</td>\n",
       "      <td>The Sherlock Holmes Book</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2015-10-20</td>\n",
       "      <td>9781465438492</td>\n",
       "      <td>1247.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Bryan D. Palmer</td>\n",
       "      <td>E.P. Thompson</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>1994-10-17</td>\n",
       "      <td>9781859840702</td>\n",
       "      <td>1040.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>Robert B. Parker</td>\n",
       "      <td>Pale Kings and Princes</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>1988-06-10</td>\n",
       "      <td>9780440200048</td>\n",
       "      <td>0824.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>Penelope Lively</td>\n",
       "      <td>The Purple Swamp Hen and Other Stories</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>9780735222052</td>\n",
       "      <td>0925.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AUTHOR                                   TITLE       GENRE  \\\n",
       "174    Patricia Briggs                       The Hob's Bargain     Fiction   \n",
       "1247                DK                The Sherlock Holmes Book    Classics   \n",
       "1040   Bryan D. Palmer                           E.P. Thompson  Nonfiction   \n",
       "824   Robert B. Parker                  Pale Kings and Princes     Fiction   \n",
       "925    Penelope Lively  The Purple Swamp Hen and Other Stories     Fiction   \n",
       "\n",
       "       PUB_DATE           ISBN FILE_NAME  \n",
       "174  2001-03-01  9780441008131  0174.txt  \n",
       "1247 2015-10-20  9781465438492  1247.txt  \n",
       "1040 1994-10-17  9781859840702  1040.txt  \n",
       "824  1988-06-10  9780440200048  0824.txt  \n",
       "925  2018-05-08  9780735222052  0925.txt  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "manifest = pd.read_csv(\"data/session_three/manifest.csv\", index_col = 0)\n",
    "manifest['PUB_DATE'] = pd.to_datetime(manifest['PUB_DATE'], format=\"%Y-%m-%d\")\n",
    "\n",
    "print(\n",
    "    f\"Number of blurbs: {len(manifest)}\",\n",
    "    f\"\\nDate range: {manifest['PUB_DATE'].dt.year.min()}--{manifest['PUB_DATE'].dt.year.max()}\",\n",
    "    f\"\\nGenres: {', '.join(manifest['GENRE'].unique().tolist())}\"\n",
    ")\n",
    "\n",
    "manifest.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b76dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "manifest.groupby('PUB_DATE')['ISBN'].count().plot(figsize = (15, 5),\n",
    "                                                  title = \"Books per Year\",\n",
    "                                                  xlabel = \"Publication Year\",\n",
    "                                                  ylabel = \"Number of Books\",\n",
    "                                                  ylim = (0, 11)\n",
    "                                                  );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3423a70",
   "metadata": {},
   "source": [
    "To make file loading easier, we'll isolate the file names from `manifest` and create a list of paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfc3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = \"data/session_three/input/\"\n",
    "paths = indir + manifest['FILE_NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc99bbe",
   "metadata": {},
   "source": [
    "Building a Topic Model\n",
    "---------------------------\n",
    "\n",
    "With this bit of preliminary work done, we're ready to build a topic model. There are numerous implementations of \n",
    "LDA modeling available, ranging from the command line utility, [MALLET] (which many of us in the DataLab use in our \n",
    "own work), to built-in APIs offered by both `gensim` and `scikit-learn`. It's tempting to use the `scikit-learn` \n",
    "API: we should be familiar with this package's conventions by now, and indeed it's quite easy to spin up a topic \n",
    "model using its API. But there's a [reported bug] in a key metric for validating LDA models in `scikit-learn`, and, \n",
    "as far as we know, this bug hasn't been fixed. Depending on your use case, this may not be a big deal. The bug has \n",
    "to do with generating a **perplexity score** from the model, which is useful for fine tuning. You, however, may not \n",
    "want to go through this process, especially if you're working in an exploratory model. In this case, it's probably \n",
    "fine to use `scikit-learn`.\n",
    "\n",
    "As for us: we'll be demonstrating how to fine tune models and will thus avoid `scikit-learn` for the workshop. \n",
    "Instead, we'll be using `tomotopy`, a Python wrapper built around Tomato, a topic modeling tool built in C++. Its \n",
    "API is fairly intuitive and comes with lots of options, which we'll leverage to build the best model possible for \n",
    "our data.\n",
    "\n",
    "[MALLET]: https://mimno.github.io/Mallet/\n",
    "[reported bug]: https://github.com/scikit-learn/scikit-learn/issues/6777"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4d79e",
   "metadata": {},
   "source": [
    "### Initializing a model\n",
    "\n",
    "Initializing a topic model with `tomotopy` is simple: just assign `LDAModel()` to a variable and declare the number \n",
    "of topics the model will generate. As we'll discuss below, determining how many topics to use is a matter of some \n",
    "debate and complexity, but for now, we'll just pick a number and move ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfba4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "\n",
    "n_topics = 5\n",
    "model = tp.LDAModel(k = n_topics, seed = 357)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75458d22",
   "metadata": {},
   "source": [
    "Now we need to add our blurbs to the model. We'll do so by using a `for` loop in conjunction with all the paths we \n",
    "created above. The only catch here is that we need to split each blurb into a list of tokens (right now they're \n",
    "stored as text blobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8671ce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1500\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    with open(path, 'r') as p:\n",
    "        doc = p.read().split()\n",
    "        model.add_doc(doc)\n",
    "        \n",
    "print(\"Number of documents:\", len(model.docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f02d07",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "\n",
    "Our model is now ready to be trained. Under the hood, this happens in an iterative fashion, so we need to set the \n",
    "total number of iterations we'd like to use to do the training. With that set, it's simply a matter of calling \n",
    "`model.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf75d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 500\n",
    "model.train(iter = n_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f54b7b",
   "metadata": {},
   "source": [
    "### Inspecting the Results\n",
    "\n",
    "With our trained on our corpus, we can access some high-level information about the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc30aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 19609 \n",
      "Total number of tokens: 129027\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Number of unique words: {len(model.used_vocabs)}\",\n",
    "    f\"\\nTotal number of tokens: {model.num_words}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94601aa3",
   "metadata": {},
   "source": [
    "For each topic, we can get the words most associated with that topic. The accompanying score is the probability of \n",
    "that word appearing in a given topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "121c074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "+ book (0.0262%), story (0.0134%), new (0.0109%), reader (0.0101%), read (0.0078%)\n",
      "Topic 1: \n",
      "+ book (0.0110%), use (0.0067%), guide (0.0065%), include (0.0063%), work (0.0060%)\n",
      "Topic 2: \n",
      "+ novel (0.0090%), new (0.0088%), war (0.0073%), man (0.0065%), time (0.0063%)\n",
      "Topic 3: \n",
      "+ life (0.0253%), story (0.0084%), live (0.0082%), year (0.0079%), new (0.0077%)\n",
      "Topic 4: \n",
      "+ just (0.0102%), make (0.0097%), friend (0.0086%), get (0.0076%), day (0.0074%)\n"
     ]
    }
   ],
   "source": [
    "for k in range(model.k):\n",
    "    top_words = model.get_topic_words(topic_id = k, top_n = 5)\n",
    "    top_words = [f\"{tup[0]} ({tup[1]:.04f}%)\" for tup in top_words]\n",
    "    print(\n",
    "        f\"Topic {k}:\",\n",
    "        f\"\\n+ {', '.join(top_words)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d8843",
   "metadata": {},
   "source": [
    "This seems to make intuitive sense: we're dealing here with several hundred book blurbs, so \"book,\" \"reader,\" and \n",
    "\"new\" are all words we'd expect to see.\n",
    "\n",
    "Since each topic has a probability score for every word, it's also possible to look at the total word distribution \n",
    "for a topic with `get_word_dist()`. This outputs an array of probabilities, which is indexed in the same order as \n",
    "`model.used_vocabs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "459ba13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "just      0.010161\n",
       "make      0.009699\n",
       "friend    0.008590\n",
       "get       0.007574\n",
       "day       0.007390\n",
       "like      0.006743\n",
       "school    0.006420\n",
       "new       0.006050\n",
       "girl      0.005958\n",
       "home      0.005727\n",
       "family    0.005727\n",
       "time      0.005681\n",
       "he        0.005542\n",
       "good      0.005496\n",
       "shes      0.005358\n",
       "start     0.005265\n",
       "food      0.004988\n",
       "want      0.004988\n",
       "love      0.004896\n",
       "help      0.004711\n",
       "little    0.004434\n",
       "best      0.004388\n",
       "come      0.004342\n",
       "night     0.004065\n",
       "recipe    0.004065\n",
       "dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dist = model.get_topic_word_dist(topic_id = 4)\n",
    "pd.Series(word_dist, index = model.used_vocabs).sort_values(ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd46e1",
   "metadata": {},
   "source": [
    "To zoom out a bit: it's also often helpful to know how large each topic is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d1dba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 23727 words\n",
      "Topic 1: 23950 words\n",
      "Topic 2: 30303 words\n",
      "Topic 3: 29590 words\n",
      "Topic 4: 21457 words\n"
     ]
    }
   ],
   "source": [
    "topic_sizes = model.get_count_by_topics()\n",
    "for k in range(0, n_topics):\n",
    "    print(f\"Topic {k}: {topic_sizes[k]} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed54467",
   "metadata": {},
   "source": [
    "Finally, we can get the topic distribution for a given document. We do so with the `docs` attribute of `model`, \n",
    "which is indexed in the same order as our documents. Here, we'll sample from `manifest`, get the associated index, \n",
    "pipe it into our model object, and return the top topic for a blurb. As with `get_topic_words()` above, the top \n",
    "topic will also return a probability score for a given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e277271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top topics for:\n",
      "+ Southern Discomfort: 4 (0.461%)\n",
      "+ Mr. and Mr. Smith: 4 (0.330%)\n",
      "+ Tattoo: 4 (0.507%)\n",
      "+ Scream Street: Invasion of the Normals: 2 (0.468%)\n",
      "+ The Encyclopedia of Guilty Pleasures: 0 (0.421%)\n"
     ]
    }
   ],
   "source": [
    "sampled_titles = manifest.sample(5).index\n",
    "\n",
    "print(\"Top topics for:\")\n",
    "for idx in sampled_titles:\n",
    "    result = model.docs[idx].get_topics(top_n = 1)\n",
    "    topic = result[0][0]\n",
    "    score = result[0][1]\n",
    "    print(f\"+ {manifest.loc[idx, 'TITLE']}: {topic} ({score:0.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383909f8",
   "metadata": {},
   "source": [
    "We can get even more granular. Every word in a document has its own associated topic, which will change depending \n",
    "on the document. This is about as close to context-sensitive semantics as we can get with this method. We'll grab \n",
    "just one title from our sampled set to show this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98139fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD</th>\n",
       "      <th>TOPIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>southern</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hospitality</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deadly</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deception</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>start</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>charm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mystery</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>series</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          WORD  TOPIC\n",
       "0     southern      4\n",
       "1  hospitality      4\n",
       "2         meet      2\n",
       "3       deadly      2\n",
       "4    deception      2\n",
       "5        start      4\n",
       "6        charm      0\n",
       "7          new      0\n",
       "8      mystery      2\n",
       "9       series      4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = model.docs[sampled_titles[0]]\n",
    "doc_word_to_topic_dist = doc.topics\n",
    "\n",
    "pd.DataFrame(zip(doc, doc_word_to_topic_dist), columns = ['WORD', 'TOPIC']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45001cfb",
   "metadata": {},
   "source": [
    "Fine Tuning: The Basics\n",
    "----------------------------\n",
    "\n",
    "All this looks good so far, but our topics are fairly general â€“ and quite large. More, the same top words appear \n",
    "across different topics in the model, which makes it difficult to interpret the specifcity of each topic. All this \n",
    "suggests that we need to make some adjustments to the way we initialize our model. But there are several different \n",
    "parameters to adjust when intializing the model, so what, then, should we change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a947e00",
   "metadata": {},
   "source": [
    "### Setting the number of topics\n",
    "\n",
    "An easy answer would be the number of topics. If, as above, your topics seem too general, it may be because you've \n",
    "too small a number of topics for the model. Increasing the number of topics you use may make the model more \n",
    "interpretable.\n",
    "\n",
    "We'll show an example. But before doing so, we'll load our files into a `tomotopy` `Corpus()` object, which will \n",
    "streamline the model initialization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95055881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomotopy.utils import Corpus\n",
    "\n",
    "corpus = Corpus()\n",
    "for path in paths:\n",
    "    with open(path, 'r') as p:\n",
    "        doc = p.read().split()\n",
    "        corpus.add_doc(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55af82d",
   "metadata": {},
   "source": [
    "Now, let's set a higher number of topics for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f11d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1500\n"
     ]
    }
   ],
   "source": [
    "n_topics = 10\n",
    "model = tp.LDAModel(k = n_topics, corpus = corpus, seed = 357)\n",
    "\n",
    "print(\"Number of documents:\", len(model.docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de378a1",
   "metadata": {},
   "source": [
    "And let's also define a quick function to help us inspect the top words for each topic. This is the same `for` loop \n",
    "we used earlier wrapped up in a callable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eab2d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_words(model, top_n = 5):\n",
    "    for k in range(model.k):\n",
    "        top_words = model.get_topic_words(topic_id = k, top_n = top_n)\n",
    "        top_words = [f\"{tup[0]} ({tup[1]:.04f}%)\" for tup in top_words]\n",
    "        print(\n",
    "            f\"Topic {k}:\",\n",
    "            f\"\\n+ {', '.join(top_words)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e588b",
   "metadata": {},
   "source": [
    "With that done, let's train a model with our new number of topics and see what the results look like. We'll use the \n",
    "same number of iterations as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a28fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "+ new (0.0369%), time (0.0228%), author (0.0188%), york (0.0185%), novel (0.0172%)\n",
      "Topic 1: \n",
      "+ book (0.0372%), story (0.0193%), reader (0.0151%), new (0.0134%), read (0.0108%)\n",
      "Topic 2: \n",
      "+ book (0.0128%), use (0.0086%), offer (0.0083%), life (0.0080%), learn (0.0071%)\n",
      "Topic 3: \n",
      "+ murder (0.0172%), mystery (0.0168%), crime (0.0090%), kill (0.0088%), killer (0.0088%)\n",
      "Topic 4: \n",
      "+ food (0.0199%), recipe (0.0172%), italian (0.0080%), eat (0.0074%), cook (0.0074%)\n",
      "Topic 5: \n",
      "+ life (0.0299%), woman (0.0165%), story (0.0154%), love (0.0151%), family (0.0126%)\n",
      "Topic 6: \n",
      "+ history (0.0129%), work (0.0127%), american (0.0125%), world (0.0088%), year (0.0085%)\n",
      "Topic 7: \n",
      "+ just (0.0120%), know (0.0100%), like (0.0089%), time (0.0088%), make (0.0085%)\n",
      "Topic 8: \n",
      "+ war (0.0159%), world (0.0111%), power (0.0081%), battle (0.0081%), king (0.0069%)\n",
      "Topic 9: \n",
      "+ child (0.0132%), little (0.0124%), animal (0.0109%), day (0.0107%), make (0.0094%)\n"
     ]
    }
   ],
   "source": [
    "model.train(iter = n_iters)\n",
    "\n",
    "print_topic_words(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d093e4",
   "metadata": {},
   "source": [
    "That looks better! Adding more topics spreads out the word distributions.\n",
    "\n",
    "Given that, what if we increased our number of topics even higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9f99a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "+ life (0.0439%), story (0.0182%), character (0.0175%), century (0.0167%), become (0.0123%)\n",
      "Topic 1: \n",
      "+ business (0.0339%), company (0.0163%), success (0.0158%), idea (0.0122%), career (0.0104%)\n",
      "Topic 2: \n",
      "+ vampire (0.0247%), magic (0.0195%), max (0.0182%), witch (0.0169%), magical (0.0143%)\n",
      "Topic 3: \n",
      "+ american (0.0273%), story (0.0245%), history (0.0200%), tell (0.0147%), great (0.0143%)\n",
      "Topic 4: \n",
      "+ music (0.0298%), film (0.0160%), black (0.0160%), universe (0.0155%), take (0.0151%)\n",
      "Topic 5: \n",
      "+ love (0.0264%), father (0.0201%), london (0.0201%), tale (0.0193%), elizabeth (0.0134%)\n",
      "Topic 6: \n",
      "+ secret (0.0143%), face (0.0139%), dark (0.0131%), world (0.0117%), power (0.0113%)\n",
      "Topic 7: \n",
      "+ sister (0.0217%), woman (0.0199%), fear (0.0181%), relationship (0.0145%), brother (0.0133%)\n",
      "Topic 8: \n",
      "+ adventure (0.0321%), book (0.0287%), friend (0.0181%), story (0.0158%), new (0.0156%)\n",
      "Topic 9: \n",
      "+ animal (0.0356%), little (0.0277%), baby (0.0209%), christmas (0.0202%), cat (0.0195%)\n",
      "Topic 10: \n",
      "+ book (0.0434%), reader (0.0287%), learn (0.0213%), read (0.0202%), child (0.0167%)\n",
      "Topic 11: \n",
      "+ big (0.0147%), box (0.0133%), set (0.0119%), machine (0.0112%), piece (0.0105%)\n",
      "Topic 12: \n",
      "+ guide (0.0296%), use (0.0160%), new (0.0157%), book (0.0149%), include (0.0136%)\n",
      "Topic 13: \n",
      "+ love (0.0356%), heart (0.0253%), author (0.0193%), romance (0.0180%), novel (0.0166%)\n",
      "Topic 14: \n",
      "+ planet (0.0155%), military (0.0142%), lego (0.0138%), president (0.0125%), war (0.0125%)\n",
      "Topic 15: \n",
      "+ team (0.0292%), game (0.0280%), sport (0.0274%), horse (0.0268%), baseball (0.0191%)\n",
      "Topic 16: \n",
      "+ man (0.0224%), miss (0.0200%), jack (0.0176%), agent (0.0176%), tom (0.0170%)\n",
      "Topic 17: \n",
      "+ recipe (0.0307%), food (0.0289%), italian (0.0132%), family (0.0128%), cook (0.0121%)\n",
      "Topic 18: \n",
      "+ story (0.0212%), volume (0.0188%), comic (0.0183%), include (0.0180%), collection (0.0178%)\n",
      "Topic 19: \n",
      "+ murder (0.0238%), mystery (0.0229%), town (0.0229%), kill (0.0139%), death (0.0128%)\n",
      "Topic 20: \n",
      "+ classic (0.0304%), penguin (0.0241%), work (0.0231%), english (0.0188%), year (0.0183%)\n",
      "Topic 21: \n",
      "+ political (0.0175%), social (0.0145%), state (0.0138%), world (0.0137%), american (0.0119%)\n",
      "Topic 22: \n",
      "+ cole (0.0196%), financial (0.0183%), money (0.0169%), city (0.0122%), ice (0.0108%)\n",
      "Topic 23: \n",
      "+ book (0.0485%), time (0.0335%), new (0.0316%), york (0.0246%), review (0.0189%)\n",
      "Topic 24: \n",
      "+ life (0.0580%), spiritual (0.0192%), world (0.0127%), self (0.0124%), book (0.0122%)\n",
      "Topic 25: \n",
      "+ emma (0.0198%), holmes (0.0179%), russell (0.0113%), sherlock (0.0104%), alpine (0.0095%)\n",
      "Topic 26: \n",
      "+ love (0.0346%), story (0.0272%), family (0.0245%), life (0.0218%), young (0.0179%)\n",
      "Topic 27: \n",
      "+ art (0.0201%), paris (0.0139%), louis (0.0116%), ford (0.0108%), famous (0.0108%)\n",
      "Topic 28: \n",
      "+ help (0.0130%), provide (0.0117%), health (0.0114%), body (0.0107%), guide (0.0105%)\n",
      "Topic 29: \n",
      "+ war (0.0643%), men (0.0152%), soldier (0.0148%), king (0.0144%), fight (0.0129%)\n",
      "Topic 30: \n",
      "+ jones (0.0138%), foot (0.0118%), longarm (0.0112%), aunt (0.0112%), junie (0.0105%)\n",
      "Topic 31: \n",
      "+ god (0.0197%), book (0.0177%), study (0.0143%), work (0.0140%), personal (0.0135%)\n",
      "Topic 32: \n",
      "+ new (0.0364%), time (0.0245%), year (0.0228%), world (0.0222%), life (0.0153%)\n",
      "Topic 33: \n",
      "+ woman (0.0576%), husband (0.0279%), life (0.0220%), wife (0.0195%), men (0.0176%)\n",
      "Topic 34: \n",
      "+ just (0.0218%), like (0.0164%), make (0.0139%), want (0.0138%), good (0.0131%)\n"
     ]
    }
   ],
   "source": [
    "n_topics = 35\n",
    "more_topics = tp.LDAModel(k = n_topics, corpus = corpus, seed = 357)\n",
    "\n",
    "more_topics.train(iter = n_iters)\n",
    "\n",
    "print_topic_words(more_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2566226",
   "metadata": {},
   "source": [
    "This also looks pretty solid. Between the two models, there appear to be some similar topics, but the second model, \n",
    "which has a higher number of topics, includes a wider range of words in the top word distrubition. While all that \n",
    "seems well and good, we don't yet have a way to determine whether an increase in the number of topics will always \n",
    "produce more interpretable results. At some point, we might start splitting hairs. In fact, we can see this \n",
    "beginning to happen in a few instances with the second model. There are a few topics above that we might prefer to \n",
    "merge into a single one. Maybe topics 23 and 32, for example, would be better off belonging together, rather than \n",
    "staying apart, as they are here.\n",
    "\n",
    "So the question is, what is an ideal number of topics?\n",
    "\n",
    "One way to approach this question would be to run through a range of different topic sizes and inspect the results. \n",
    "In some cases, it can be perfectly valid to pick the number of topics that appears to be the most interpretable for \n",
    "you and the questions you have about your corpus. But there are also a few metrics we can use to measure the \n",
    "quality of a given model in terms of the underlying data it represents. Sometimes these metrics lead to models that \n",
    "aren't quite as interpretable, but they also help us make a more empirically grounded assessment of the resultant \n",
    "topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9267d",
   "metadata": {},
   "source": [
    "### Perplexity\n",
    "\n",
    "The first of these measures is **perplexity**. In text mining and natural language processing, we use perplexity \n",
    "scoring to evaluate how well a model predicts an unseen set of words. Essentially, it measures how \"surprised\" a \n",
    "model is by a sequence of unseen words. The lower the perplexity, the more your model is capable of mapping \n",
    "predictions against the data it's been trained on.\n",
    "\n",
    "```{margin} More on perplexity\n",
    "FIND A GOOD EXPLAINER FOR PERPLEXITY\n",
    "```\n",
    "\n",
    "When you train a `tomotopy` model object, the model records a perplexity score for the training run. We can access \n",
    "this score as an attribute for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d6a87c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity score for the 10-topic model: 9767.1118 \n",
      "Perplexity score for the 35-topic model: 10134.3682\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Perplexity score for the {model.k}-topic model: {model.perplexity:0.4f}\",\n",
    "    f\"\\nPerplexity score for the {more_topics.k}-topic model: {more_topics.perplexity:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e8782",
   "metadata": {},
   "source": [
    "Interestingly, in this instance, the model with the smaller number of topics has a better perplexity score than the \n",
    "one with more topics. This would suggest that the first model is better fitted to our data and is thus a \"better\" \n",
    "model.\n",
    "\n",
    "It also suggests that there may be a topic size between these two sizes that has an even better perplexity score. \n",
    "We can test to see whether this is the case by constructing a `for` loop, in which we iterate through a number of \n",
    "different topic sizes, train a model with those sizes, and record the resultant perplexity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae2f6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topic_range = range(10, 31)\n",
    "\n",
    "perplexity_scores = []\n",
    "for k in n_topic_range:\n",
    "    model = tp.LDAModel(k = k, corpus = corpus, seed = 357)\n",
    "    model.train(iter = n_iters)\n",
    "    perplexity_scores.append({'N_TOPICS': k, 'SCORE': model.perplexity})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1925d7d2",
   "metadata": {},
   "source": [
    "Let's convert the results to a dataframe and, while we're at it, train a model with the best-scoring number of \n",
    "topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0b9f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_scores = pd.DataFrame(perplexity_scores)\n",
    "perplexity_scores = perplexity_scores.sort_values('SCORE')\n",
    "\n",
    "best_n_topic = perplexity_scores.nsmallest(1, 'SCORE')['N_TOPICS'].item()\n",
    "best_model = tp.LDAModel(k = best_n_topic, corpus = corpus, seed = 357)\n",
    "best_model.train(iter = n_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46843d79",
   "metadata": {},
   "source": [
    "Here are the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69bf9bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_TOPICS</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>9743.965507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>9767.111839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>9817.241300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>9854.947514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>9901.255709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>9960.354987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>9980.877440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23</td>\n",
       "      <td>9992.182970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>10016.706893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>10072.478196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>10088.561813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>10096.603287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>10097.970560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>10103.504066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10141.311590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N_TOPICS         SCORE\n",
       "12        22   9743.965507\n",
       "0         10   9767.111839\n",
       "17        27   9817.241300\n",
       "1         11   9854.947514\n",
       "7         17   9901.255709\n",
       "18        28   9960.354987\n",
       "5         15   9980.877440\n",
       "13        23   9992.182970\n",
       "8         18  10016.706893\n",
       "14        24  10072.478196\n",
       "11        21  10088.561813\n",
       "3         13  10096.603287\n",
       "10        20  10097.970560\n",
       "6         16  10103.504066\n",
       "2         12  10141.311590"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_scores.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86dfb0",
   "metadata": {},
   "source": [
    "In this instance, it looks like 22 topics is the best, though the difference between the perplexity scores for that \n",
    "model and the next best-scoring model, our 10-topic model, are relatively small. Given this, if you find that a \n",
    "10-topic model is more interpretable, you may choose to make a compromise on perplexity and go with that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e44e273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "+ book (0.0318%), story (0.0279%), time (0.0214%), new (0.0184%), novel (0.0166%)\n",
      "Topic 1: \n",
      "+ love (0.0391%), woman (0.0364%), life (0.0232%), mother (0.0203%), family (0.0184%)\n",
      "Topic 2: \n",
      "+ life (0.0400%), world (0.0225%), great (0.0157%), year (0.0137%), story (0.0134%)\n",
      "Topic 3: \n",
      "+ just (0.0201%), like (0.0149%), make (0.0126%), want (0.0124%), know (0.0122%)\n",
      "Topic 4: \n",
      "+ book (0.0269%), child (0.0241%), school (0.0190%), young (0.0186%), kid (0.0169%)\n",
      "Topic 5: \n",
      "+ war (0.0349%), world (0.0182%), battle (0.0152%), fight (0.0131%), force (0.0105%)\n",
      "Topic 6: \n",
      "+ new (0.0383%), york (0.0232%), art (0.0163%), music (0.0135%), street (0.0100%)\n",
      "Topic 7: \n",
      "+ god (0.0361%), spiritual (0.0212%), book (0.0164%), religious (0.0112%), religion (0.0100%)\n",
      "Topic 8: \n",
      "+ home (0.0218%), house (0.0215%), cat (0.0159%), horse (0.0148%), dog (0.0120%)\n",
      "Topic 9: \n",
      "+ adventure (0.0244%), story (0.0237%), tale (0.0155%), book (0.0153%), feature (0.0129%)\n",
      "Topic 10: \n",
      "+ work (0.0272%), classic (0.0211%), year (0.0168%), penguin (0.0154%), literature (0.0133%)\n",
      "Topic 11: \n",
      "+ book (0.0268%), include (0.0163%), help (0.0130%), new (0.0126%), provide (0.0113%)\n",
      "Topic 12: \n",
      "+ food (0.0269%), recipe (0.0257%), family (0.0111%), cook (0.0105%), italian (0.0102%)\n",
      "Topic 13: \n",
      "+ city (0.0249%), london (0.0151%), empire (0.0107%), elizabeth (0.0099%), king (0.0096%)\n",
      "Topic 14: \n",
      "+ new (0.0304%), author (0.0245%), time (0.0231%), bestselling (0.0221%), york (0.0197%)\n",
      "Topic 15: \n",
      "+ travel (0.0194%), sea (0.0168%), new (0.0130%), top (0.0121%), map (0.0119%)\n",
      "Topic 16: \n",
      "+ use (0.0326%), step (0.0179%), simple (0.0150%), book (0.0138%), create (0.0131%)\n",
      "Topic 17: \n",
      "+ team (0.0175%), baseball (0.0170%), sport (0.0164%), hockey (0.0117%), player (0.0111%)\n",
      "Topic 18: \n",
      "+ family (0.0138%), new (0.0136%), secret (0.0135%), know (0.0124%), old (0.0124%)\n",
      "Topic 19: \n",
      "+ magic (0.0159%), king (0.0141%), return (0.0138%), kingdom (0.0116%), power (0.0105%)\n",
      "Topic 20: \n",
      "+ american (0.0246%), history (0.0203%), political (0.0167%), america (0.0158%), state (0.0132%)\n",
      "Topic 21: \n",
      "+ business (0.0122%), problem (0.0105%), success (0.0101%), health (0.0099%), people (0.0097%)\n"
     ]
    }
   ],
   "source": [
    "print_topic_words(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b01c17",
   "metadata": {},
   "source": [
    "### Coherence\n",
    "\n",
    "If you're having trouble mapping perplexity scores onto interpretable results, you might use a **coherence score** \n",
    "instead. Coherence scores measure the degree of semantic similarity among the words in a topic. Some people prefer \n",
    "to use coherence scoring in place of perplexity because these scores help distinguish the difference between topics \n",
    "that fit snugly on consistent word co-occurence and those that are artifacts of statistical inference.\n",
    "\n",
    "There are a few ways to calculate coherence scores. We'll use `c_v` coherence, which uses the two kinds of text \n",
    "similarity we've already seen in the workshop: pointwise mutual information (PMI) and cosine similarity. This \n",
    "method takes the co-occurence counts of top words in a given topic and calculates a PMI score for each word. Then, \n",
    "it looks to every other topic in the model and calculates a PMI score for the present topic's words and those in \n",
    "the other topics. This results in a series of vectors, which are then measured with cosine similarity.\n",
    "\n",
    "That's a mouthful, but `tomotoy` makes implementing it a breeze. Let's look at the score for the best model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30a5ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score: 0.6051\n"
     ]
    }
   ],
   "source": [
    "from tomotopy.coherence import Coherence\n",
    "\n",
    "coherence = Coherence(best_model, coherence = 'c_v')\n",
    "print(f\"Coherence score: {coherence.get_score():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecf8d6",
   "metadata": {},
   "source": [
    "Like with perplexity, we can construct a `for` loop and look for the best score among a set of different topic \n",
    "sizes. Here, we're looking for the highest score, which will be a number between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5fa4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topic_range = range(10, 31)\n",
    "\n",
    "coherence_scores = []\n",
    "for k in n_topic_range:\n",
    "    model = tp.LDAModel(k = k, corpus = corpus, seed = 357)\n",
    "    model.train(iter = n_iters)\n",
    "    coherence = Coherence(model, coherence = 'c_v')\n",
    "    coherence_scores.append({'N_TOPICS': k, 'SCORE': coherence.get_score()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f2c7a",
   "metadata": {},
   "source": [
    "Let's format the scores, find the best one, and train a model on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bb8acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_scores = pd.DataFrame(coherence_scores)\n",
    "coherence_scores = coherence_scores.sort_values('SCORE', ascending = False)\n",
    "\n",
    "best_n_topic = perplexity_scores.nlargest(1, 'SCORE')['N_TOPICS'].item()\n",
    "best_model = tp.LDAModel(k = best_n_topic, corpus = corpus, seed = 357)\n",
    "best_model.train(iter = n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dd40915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_TOPICS</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29</td>\n",
       "      <td>0.655928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>0.654988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>0.648859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>0.645488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23</td>\n",
       "      <td>0.624086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>0.615611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26</td>\n",
       "      <td>0.608920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>0.605131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>0.599103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>0.595933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>0.579910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>0.578593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.570283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>0.558606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.558422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.554183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>0.534431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.521571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.516569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.511096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.499647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N_TOPICS     SCORE\n",
       "19        29  0.655928\n",
       "18        28  0.654988\n",
       "17        27  0.648859\n",
       "20        30  0.645488\n",
       "13        23  0.624086\n",
       "15        25  0.615611\n",
       "16        26  0.608920\n",
       "12        22  0.605131\n",
       "11        21  0.599103\n",
       "14        24  0.595933\n",
       "8         18  0.579910\n",
       "10        20  0.578593\n",
       "5         15  0.570283\n",
       "7         17  0.558606\n",
       "9         19  0.558422\n",
       "3         13  0.554183\n",
       "6         16  0.534431\n",
       "4         14  0.521571\n",
       "2         12  0.516569\n",
       "0         10  0.511096\n",
       "1         11  0.499647"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6eaef",
   "metadata": {},
   "source": [
    "Looks like a 29-topic model wins out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f679149d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "+ life (0.0506%), book (0.0211%), live (0.0142%), experience (0.0133%), offer (0.0124%)\n",
      "Topic 1: \n",
      "+ war (0.0329%), soldier (0.0166%), american (0.0133%), men (0.0133%), military (0.0112%)\n",
      "Topic 2: \n",
      "+ baby (0.0162%), feel (0.0140%), fly (0.0129%), touch (0.0123%), rat (0.0112%)\n",
      "Topic 3: \n",
      "+ friend (0.0323%), girl (0.0301%), love (0.0296%), old (0.0195%), brother (0.0150%)\n",
      "Topic 4: \n",
      "+ new (0.0424%), book (0.0368%), time (0.0296%), york (0.0271%), review (0.0179%)\n",
      "Topic 5: \n",
      "+ just (0.0196%), time (0.0159%), make (0.0146%), like (0.0145%), know (0.0132%)\n",
      "Topic 6: \n",
      "+ guide (0.0242%), travel (0.0233%), top (0.0170%), new (0.0166%), eyewitness (0.0161%)\n",
      "Topic 7: \n",
      "+ world (0.0338%), human (0.0310%), new (0.0224%), people (0.0152%), way (0.0142%)\n",
      "Topic 8: \n",
      "+ star (0.0243%), war (0.0211%), lego (0.0170%), universe (0.0138%), set (0.0124%)\n",
      "Topic 9: \n",
      "+ london (0.0222%), ben (0.0114%), lady (0.0107%), freud (0.0100%), lacey (0.0093%)\n",
      "Topic 10: \n",
      "+ classic (0.0288%), work (0.0252%), english (0.0194%), penguin (0.0191%), literature (0.0180%)\n",
      "Topic 11: \n",
      "+ god (0.0330%), magic (0.0210%), king (0.0191%), return (0.0158%), kingdom (0.0153%)\n",
      "Topic 12: \n",
      "+ guide (0.0227%), use (0.0226%), book (0.0213%), step (0.0180%), learn (0.0163%)\n",
      "Topic 13: \n",
      "+ people (0.0145%), show (0.0136%), business (0.0124%), think (0.0123%), study (0.0121%)\n",
      "Topic 14: \n",
      "+ music (0.0222%), sport (0.0163%), team (0.0155%), star (0.0134%), baseball (0.0130%)\n",
      "Topic 15: \n",
      "+ home (0.0270%), year (0.0245%), family (0.0219%), life (0.0193%), old (0.0177%)\n",
      "Topic 16: \n",
      "+ book (0.0458%), reader (0.0166%), read (0.0156%), child (0.0155%), feature (0.0147%)\n",
      "Topic 17: \n",
      "+ health (0.0171%), program (0.0128%), body (0.0124%), plan (0.0117%), help (0.0114%)\n",
      "Topic 18: \n",
      "+ murder (0.0317%), town (0.0270%), mystery (0.0258%), death (0.0188%), police (0.0137%)\n",
      "Topic 19: \n",
      "+ comic (0.0279%), cat (0.0228%), poem (0.0217%), animal (0.0199%), cole (0.0165%)\n",
      "Topic 20: \n",
      "+ tale (0.0337%), horse (0.0263%), ship (0.0189%), adventure (0.0164%), sea (0.0144%)\n",
      "Topic 21: \n",
      "+ christmas (0.0234%), tree (0.0168%), house (0.0156%), jack (0.0135%), night (0.0127%)\n",
      "Topic 22: \n",
      "+ political (0.0253%), state (0.0200%), american (0.0149%), america (0.0144%), power (0.0121%)\n",
      "Topic 23: \n",
      "+ story (0.0397%), year (0.0211%), world (0.0173%), life (0.0138%), become (0.0121%)\n",
      "Topic 24: \n",
      "+ art (0.0255%), work (0.0189%), history (0.0158%), artist (0.0143%), life (0.0141%)\n",
      "Topic 25: \n",
      "+ century (0.0257%), history (0.0161%), john (0.0138%), war (0.0130%), figure (0.0092%)\n",
      "Topic 26: \n",
      "+ woman (0.0427%), love (0.0375%), life (0.0276%), mother (0.0167%), heart (0.0153%)\n",
      "Topic 27: \n",
      "+ new (0.0268%), author (0.0216%), novel (0.0171%), time (0.0158%), series (0.0158%)\n",
      "Topic 28: \n",
      "+ world (0.0165%), secret (0.0137%), know (0.0133%), face (0.0098%), dark (0.0096%)\n",
      "Topic 29: \n",
      "+ recipe (0.0304%), food (0.0279%), family (0.0143%), cook (0.0133%), drink (0.0129%)\n"
     ]
    }
   ],
   "source": [
    "print_topic_words(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9479d",
   "metadata": {},
   "source": [
    "Fine Tuning: Advanced\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfeda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
