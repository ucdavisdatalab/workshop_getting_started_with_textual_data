
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. Cleaning and Counting &#8212; Getting Started with Textual Data</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >let toggleHintShow = 'Click to show';</script>
    <script >let toggleHintHide = 'Click to hide';</script>
    <script >let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Corpus Analytics" href="04_corpus-analytics.html" />
    <link rel="prev" title="2. From Text to Data" href="02_from-text-to-data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/datalab-logo-full-color-rgb.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Getting Started with Textual Data</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Overview
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_logistics.html">
   1. Before We Begin…
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_from-text-to-data.html">
   2. From Text to Data
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Cleaning and Counting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_corpus-analytics.html">
   4. Corpus Analytics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_clustering-and-classification.html">
   5. Clustering and Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_topic-modeling.html">
   6. Topic Modeling
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/03_cleaning-and-counting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ucdavisdatalab/workshop_getting_started_with_textual_data"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ucdavisdatalab/workshop_getting_started_with_textual_data/issues/new?title=Issue%20on%20page%20%2F03_cleaning-and-counting.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ucdavisdatalab/workshop_getting_started_with_textual_data/master?urlpath=tree/03_cleaning-and-counting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-cleaning-basics">
   3.1. Text Cleaning: Basics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-normalization">
     3.1.1. Case normalization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#removing-punctuation">
     3.1.2. Removing punctuation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#removing-numbers">
     3.1.3. Removing numbers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-formatting">
     3.1.4. Text formatting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#removing-stop-words">
     3.1.5. Removing stop words
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#words-with-high-occurence">
       3.1.5.1. Words with high occurence
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#defining-a-stop-list">
       3.1.5.2. Defining a stop list
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#iteratively-building-stop-lists">
       3.1.5.3. Iteratively building stop lists
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-cleaning-advanced">
   3.2. Text Cleaning: Advanced
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stemming">
     3.2.1. Stemming
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lemmatizing">
     3.2.2. Lemmatizing
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#part-of-speech-tags-and-dependency-parsing">
       3.2.2.1. Part-of-speech tags and dependency parsing
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sample-lemmatization-workflow">
       3.2.2.2. Sample lemmatization workflow
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chunking-with-n-grams">
   3.3. Chunking with N-Grams
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="cleaning-and-counting">
<h1><span class="section-number">3. </span>Cleaning and Counting<a class="headerlink" href="#cleaning-and-counting" title="Permalink to this headline">¶</a></h1>
<p>At the end of the last chapter, we caught a glimpse of the complexities involved in working with textual data. Text
is incredibly unruly. It presents a number of challenges – which stem as much from general truths about linguistic
phenomena as they do from the idiosyncracies of data representation – that we’ll need to address so that we may
formalize text in a computationally-tractable manner.</p>
<p>As we’ve also seen, once we’ve formalized textual data, a key way we can start to gain some insight about that data
is by counting words. Nearly all methods in text analytics begin by counting the number of times a word occurs and
taking note of the context in which that word occurs. With these two pieces of information, <strong>counts</strong> and
<strong>context</strong>, we can identify relationships among words and, on this basis, formulate interpretations about the texts we’re studying.</p>
<p>This chapter, then, will discuss how to wrangle the messiness of text in a way that will let us start counting.
We’ll continue with our single text file (Mary Shelley’s <em>Frankenstein</em>) and learn how to prepare text so as to
generate valuable metrics about the words within it. Later workshops will build on what we’ve learned here by
applying those metrics to multiple texts.</p>
<div class="admonition-learning-objectives admonition">
<p class="admonition-title">Learning Objectives</p>
<p>By the end of this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Clean textual data with a variety of processes</p></li>
<li><p>Recognize how these processes change the findings of text analysis</p></li>
<li><p>Explain why you might choose to do some cleaning steps but not others</p></li>
<li><p>Implement preliminary counting operations on cleaned data</p></li>
<li><p>Use a statistical measure (pointwise mutual information) to measure the uniqueness of phrases</p></li>
</ul>
</div>
<div class="section" id="text-cleaning-basics">
<h2><span class="section-number">3.1. </span>Text Cleaning: Basics<a class="headerlink" href="#text-cleaning-basics" title="Permalink to this headline">¶</a></h2>
<p>To begin: think back to the end of the last chapter. There, we discussed a few differences between how computers
represent and process textual data and our own way of reading. One of the key differences between these two poles
involves details like spelling or capitalization. For us, the <em>meaning</em> of text tends to cut across these details.
But they make all the difference in how computers track information. Accordingly, if we want to work at a higher
order of meaning, not just character sequences, we’ll need to eliminate as many variances as possible in textual
data.</p>
<p>First and foremost, we’ll need to <strong>clean</strong> our text, removing things like punctuation and handling variances in
word casing, even spelling. This entire process will happen in steps. Typically, they include:</p>
<ol class="simple">
<li><p>Resolving word cases</p></li>
<li><p>Removing punctuation</p></li>
<li><p>Removing numbers</p></li>
<li><p>Removing extra whitespaces</p></li>
<li><p>Removing “stop words”</p></li>
</ol>
<p>Note however that <em>there is no pre-set way to clean text</em>. The steps you need to perform all depend on your data
and the questions you have about it. We’ll walk through each of these steps below and, along the way, compare how
they alter the original text to show why you might (or might not) implement them.</p>
<p>To make these comparisons, let’s first load in <em>Frankenstein</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/session_one/shelley_frankenstein.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">frankenstein</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We’ll also define a simple function to count words. This will help us quickly check the results of a cleaning step.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">set()</span></code> in conjunction with a dictionary will allow us to pre-define the vocabulary space for which we need
to generate counts. This removes the need to perform the <code class="docutils literal notranslate"><span class="pre">if...else</span></code> check from earlier.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">count_words</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">word_counts</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">doc</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
        <span class="n">word_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
    <span class="k">return</span> <span class="n">word_counts</span>
</pre></div>
</div>
</div>
</div>
<p>Using this function, let’s store the original number of unique words we generated from <em>Frankenstein</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">original_counts</span> <span class="o">=</span> <span class="n">count_words</span><span class="p">(</span><span class="n">frankenstein</span><span class="p">)</span>
<span class="n">n_unique_original</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_counts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original number of unique words:&quot;</span><span class="p">,</span> <span class="n">n_unique_original</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original number of unique words: 11590
</pre></div>
</div>
</div>
</div>
<div class="section" id="case-normalization">
<h3><span class="section-number">3.1.1. </span>Case normalization<a class="headerlink" href="#case-normalization" title="Permalink to this headline">¶</a></h3>
<p>The first step in cleaning is straightforward. Since our computer treats capitalized and lowercase letters as two
different things, we’ll need to collapse them together. This will eliminate problems like “the”/”The” and
“letter”/”Letter.” It’s standard to change all letters to their lowercase forms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned</span> <span class="o">=</span> <span class="n">frankenstein</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This should reduce the number of unique words in the novel. Let’s check.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned_counts</span> <span class="o">=</span> <span class="n">count_words</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
<span class="n">n_unique_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cleaned_counts</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Unique words:&quot;</span><span class="p">,</span> <span class="n">n_unique_words</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="s2">&quot;Difference in word counts between our original count and the lowercase count:&quot;</span><span class="p">,</span> 
    <span class="n">n_unique_original</span> <span class="o">-</span> <span class="n">n_unique_words</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unique words: 11219 
Difference in word counts between our original count and the lowercase count: 371
</pre></div>
</div>
</div>
</div>
<p>Sanity check: are we going to face the same problems from before?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Is &#39;Letter&#39; in `normalized`?&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;Letter&quot;</span> <span class="ow">in</span> <span class="n">cleaned</span><span class="p">),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="s2">&quot;Number of times &#39;the&#39; appears:&quot;</span><span class="p">,</span> <span class="n">cleaned_counts</span><span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Is &#39;Letter&#39; in `normalized`? False 
Number of times &#39;the&#39; appears: 4152
</pre></div>
</div>
</div>
</div>
<p>So far so good. In the above output, we can also see that “the” has become even more prominent in the counts: we
found ~250 more instances of this word after changing its case (it was 3897 earlier).</p>
</div>
<div class="section" id="removing-punctuation">
<h3><span class="section-number">3.1.2. </span>Removing punctuation<a class="headerlink" href="#removing-punctuation" title="Permalink to this headline">¶</a></h3>
<p>It’s now time to tackle punctuation. This step is a bit trickier, and typically it involves a lot of going back and
forth between inspecting the original text and the output. This is because punctuation marks have different uses,
so they can’t all be handled in the same way.</p>
<p>Consider the following string:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;I&#39;m a self-taught programmer.&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title">Want to practice regex?</p>
<p><a class="reference external" href="https://regex101.com/">regex101</a> offers an interactive regex viewer with lots of explanations.</p>
</div>
<p>It seems most sensible to remove punctuation with some combination of <a class="reference external" href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a>, or “regex,” and the
<code class="docutils literal notranslate"><span class="pre">re.sub()</span></code> function (which substitutes a regex sequence for something else). For example, we could use regex to
identify anything that is <em>not</em> (<code class="docutils literal notranslate"><span class="pre">^</span></code>) a word (<code class="docutils literal notranslate"><span class="pre">\w</span></code>) or a space (<code class="docutils literal notranslate"><span class="pre">\s</span></code>) and remove it.</p>
<p>That would look like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>

<span class="nb">print</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^\w\s]&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Im a selftaught programmer
</pre></div>
</div>
</div>
</div>
<p>This method has some advantages. For example, it sticks the <em>m</em> in “I’m” back to the <em>I</em>. While this isn’t perfect,
as long as we remember that, whenever we see “Im,” we mean “I’m,” it’s doable – and it’s better than the
alternative: had we replaced punctuation with a space, we would have “I m.” When split apart, those two letters
would be much harder to piece back together.</p>
<p>That said, this method also sticks “self” and “taught” together, which we don’t want. It would be better to
separate those two words than to create a new one altogether. Ultimately, this is a <strong>tokenization</strong> question: what
do we define as acceptable tokens in our data, and how are we going to create those tokens? If you’re interested in
studying phrases that are hyphenated, you might not want to do any of this and simply leave the hyphens as they
are.</p>
<p>In our case, we’ll be taking them out. The best way to handle different punctuation conventions is to process
punctuation marks in stages. First, remove hyphens, then remove other punctuation marks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^\w\s]&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Im a self taught programmer
</pre></div>
</div>
</div>
</div>
<p>Let’s use this same logic on <code class="docutils literal notranslate"><span class="pre">cleaned</span></code>. Note here that we’re actually going to use two different kinds of
hyphens, the en dash (-) and the em dash (—). They look very similar in plain text, but they have diferent
character codes, and typesetters often use the latter when printing things like dates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[-—]&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
<span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^\w\s]&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cleaned</span><span class="p">[:</span><span class="mi">353</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>letter 1

_to mrs saville england_


st petersburgh dec 11th 17 


you will rejoice to hear that no disaster has accompanied the
commencement of an enterprise which you have regarded with such evil
forebodings i arrived here yesterday and my first task is to assure
my dear sister of my welfare and increasing confidence in the success
of my undertaking
</pre></div>
</div>
</div>
</div>
<p>That’s coming along nicely, but why didn’t those underscores get removed? Well, regex standards class underscores
(or “lowlines”) as word characters, meaning they class these characters along with the alphabet and numbers,
rather than punctuation. So when we used <code class="docutils literal notranslate"><span class="pre">^\w</span></code> to find anything that isn’t a word, this saved underscores from the
chopping block.</p>
<p>To complete our punctuation removal, then, we’ll remove these characters as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you didn’t want to do this separately, you could always include underscores in your code for handling hyphens.
That said, punctuation removal is almost always a multi-step process, the honing of which involves multiple
iterations. If you’re interested to learn more, Laura Turner O’Hara has a <a class="reference external" href="https://programminghistorian.org/en/lessons/cleaning-ocrd-text-with-regular-expressions">tutorial</a> on using regex to clean dirty
OCR, which offers a particularly good example of how extended the process of punctuation removal can become.</p>
</div>
</div>
<div class="section" id="removing-numbers">
<h3><span class="section-number">3.1.3. </span>Removing numbers<a class="headerlink" href="#removing-numbers" title="Permalink to this headline">¶</a></h3>
<p>With our punctuation removed, we can turn our attention to numbers. They should present less of a problem. While
our regex method above ended up keeping them around, we can remove them by simply finding characters 0-9 and
replacing them with a blank.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[0-9]&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we’ve removed punctuation and numbers, we’ll see a significant decrease in our unique word counts. This is
because of the way our computers were handling word differences: remember that “letter;” and “letter” were counted separately before. Likewise, our computers were counting spans of digits as words. But with all that removed, we’re
left with only words.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned_counts</span> <span class="o">=</span> <span class="n">count_words</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
<span class="n">n_unique_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cleaned_counts</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of unique words after removing punctuation and numbers:&quot;</span><span class="p">,</span> <span class="n">n_unique_words</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of unique words after removing punctuation and numbers: 6992
</pre></div>
</div>
</div>
</div>
<p>That’s nearly a 40% reduction in the number of unique words!</p>
</div>
<div class="section" id="text-formatting">
<h3><span class="section-number">3.1.4. </span>Text formatting<a class="headerlink" href="#text-formatting" title="Permalink to this headline">¶</a></h3>
<p>Our punctuation and number removal process introduced a lot of extra spaces into the text. Look at the first few
lines, as an example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned</span><span class="p">[:</span><span class="mi">76</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;letter \n\nto mrs saville england\n\n\nst petersburgh dec th  \n\n\nyou will rejoice&#39;
</pre></div>
</div>
</div>
</div>
<p>We’ll need to remove those, along with things like newlines (<code class="docutils literal notranslate"><span class="pre">\n</span></code>) and tabs (<code class="docutils literal notranslate"><span class="pre">\t</span></code>). There are regex patterns for
doing so, but Python’s <code class="docutils literal notranslate"><span class="pre">split()</span></code> very usefully captures any whitespace characters, not just single spaces between
words (in fact, the function we defined above, <code class="docutils literal notranslate"><span class="pre">count_words()</span></code>, has been doing this all along). So tokenizing our
text as before will also take care of this step.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned</span> <span class="o">=</span> <span class="n">cleaned</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>And with that, we are back to the list representation of <em>Frankenstein</em> that we worked with in the last chapter –
but this time, our metrics are much more robust. Let’s store <code class="docutils literal notranslate"><span class="pre">cleaned</span></code> in a <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> series so we can quickly
count and plot the remaining words. We run <code class="docutils literal notranslate"><span class="pre">value_counts()</span></code> on the series to get our counts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">cleaned_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cleaned_counts</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;COUNT&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>COUNT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>the</th>
      <td>4194</td>
    </tr>
    <tr>
      <th>and</th>
      <td>2976</td>
    </tr>
    <tr>
      <th>i</th>
      <td>2850</td>
    </tr>
    <tr>
      <th>of</th>
      <td>2642</td>
    </tr>
    <tr>
      <th>to</th>
      <td>2094</td>
    </tr>
    <tr>
      <th>my</th>
      <td>1776</td>
    </tr>
    <tr>
      <th>a</th>
      <td>1391</td>
    </tr>
    <tr>
      <th>in</th>
      <td>1129</td>
    </tr>
    <tr>
      <th>was</th>
      <td>1021</td>
    </tr>
    <tr>
      <th>that</th>
      <td>1017</td>
    </tr>
    <tr>
      <th>me</th>
      <td>867</td>
    </tr>
    <tr>
      <th>but</th>
      <td>687</td>
    </tr>
    <tr>
      <th>had</th>
      <td>686</td>
    </tr>
    <tr>
      <th>with</th>
      <td>667</td>
    </tr>
    <tr>
      <th>he</th>
      <td>608</td>
    </tr>
    <tr>
      <th>you</th>
      <td>574</td>
    </tr>
    <tr>
      <th>which</th>
      <td>558</td>
    </tr>
    <tr>
      <th>it</th>
      <td>547</td>
    </tr>
    <tr>
      <th>his</th>
      <td>535</td>
    </tr>
    <tr>
      <th>as</th>
      <td>528</td>
    </tr>
    <tr>
      <th>not</th>
      <td>510</td>
    </tr>
    <tr>
      <th>for</th>
      <td>498</td>
    </tr>
    <tr>
      <th>on</th>
      <td>460</td>
    </tr>
    <tr>
      <th>by</th>
      <td>460</td>
    </tr>
    <tr>
      <th>this</th>
      <td>402</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="removing-stop-words">
<h3><span class="section-number">3.1.5. </span>Removing stop words<a class="headerlink" href="#removing-stop-words" title="Permalink to this headline">¶</a></h3>
<p>With the first few steps of our text cleaning done, we can take a closer look at the output. Inspecting the 25-most
frequent words in <em>Frankenstein</em> shows a pattern: nearly all of them are what we call <strong>deictics</strong>, or words that
are highly dependent on the contexts in which they appear. We use these constantly to refer to specific times,
places, and persons – indeed, they’re the very sinew of language, and their high frequency counts reflect this.</p>
<div class="section" id="words-with-high-occurence">
<h4><span class="section-number">3.1.5.1. </span>Words with high occurence<a class="headerlink" href="#words-with-high-occurence" title="Permalink to this headline">¶</a></h4>
<p>We can see the full extent to which we rely on these kinds of words if we plot our counts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned_counts</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s2">&quot;Count&quot;</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;Word&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/03_cleaning-and-counting_39_0.png" src="_images/03_cleaning-and-counting_39_0.png" />
</div>
</div>
<p>See that giant drop? Let’s look at the 200-most frequent words and sample more words from the series index (which
is the x axis). We’ll put this code into a function, as we’ll be looking at a number of graphs in this section.</p>
<div class="margin sidebar">
<p class="sidebar-title">How to sample xticks:</p>
<p>Define a range of values from <code class="docutils literal notranslate"><span class="pre">0</span></code> to <code class="docutils literal notranslate"><span class="pre">n</span></code> (in this case, <code class="docutils literal notranslate"><span class="pre">n</span></code> will be <code class="docutils literal notranslate"><span class="pre">n_words</span></code>). Set the step count to your desired
granularity (here we use <code class="docutils literal notranslate"><span class="pre">5</span></code>).</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_counts</span><span class="p">(</span><span class="n">word_counts</span><span class="p">,</span> <span class="n">n_words</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">label_sample</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>    
    <span class="n">xticks_sample</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_words</span><span class="p">,</span> <span class="n">label_sample</span><span class="p">)</span>
    
    <span class="n">word_counts</span><span class="p">[:</span><span class="n">n_words</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
        <span class="n">ylabel</span> <span class="o">=</span> <span class="s2">&quot;Count&quot;</span><span class="p">,</span> 
        <span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;Word&quot;</span><span class="p">,</span>
        <span class="n">xticks</span> <span class="o">=</span> <span class="n">xticks_sample</span><span class="p">,</span>
        <span class="n">rot</span> <span class="o">=</span> <span class="mi">90</span>
    <span class="p">);</span>

<span class="n">plot_counts</span><span class="p">(</span><span class="n">cleaned_counts</span><span class="p">,</span> <span class="n">n_words</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">label_sample</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/03_cleaning-and-counting_41_0.png" src="_images/03_cleaning-and-counting_41_0.png" />
</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title">Further context:</p>
<p>The phenomenon we are discussing here is describable in terms of <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf’s law</a>, which states that, for certain types
of data, the rank-frequency distribution is an inverse relation. That is, the top-most frequent element in the data
will occur twice as often as the second-most frequent element, which will in turn occur twice as often as the
third-most frequent element, etc.</p>
</div>
<p>Only a few non-deictic words appear in the first half of this graph – “eyes,” “night,” “death,” for example. All
else are words like “my,” “from,” “their,” etc. And all of these words have screamingly high frequency counts. In
fact, the 50-most frequent words in <em>Frankenstein</em> comprise nearly 50% of the total number of words in the novel!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top_fifty_sum</span> <span class="o">=</span> <span class="n">cleaned_counts</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">total_word_sum</span> <span class="o">=</span> <span class="n">cleaned_counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Total percentage of 50-most frequent words: </span><span class="si">{</span><span class="n">top_fifty_sum</span> <span class="o">/</span> <span class="n">total_word_sum</span><span class="si">:</span><span class="s2">.02f</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total percentage of 50-most frequent words: 0.48%
</pre></div>
</div>
</div>
</div>
<p>The problem here is that, even though these highly-occurrent words help us say what we mean, they paradoxically
don’t seem to have much meaning in and of themselves. What can we determine about the word “it” without some kind
of point of reference? How meaningful is “the”? These words are so common and so context-dependent that it’s
difficult to find much to say about them in and of themselves. Worse still, every novel we put through the above
analyses is going to have a very similar distribution in terms – they’re just a general fact of language.</p>
<p>If we wanted, then, to surface what <em>Frankenstein</em> is about, we’ll need to handle these words. The most common way
to do this is to simply remove them, or <strong>stop</strong> them out. But how do we know which <strong>stop words</strong> to remove?</p>
</div>
<div class="section" id="defining-a-stop-list">
<h4><span class="section-number">3.1.5.2. </span>Defining a stop list<a class="headerlink" href="#defining-a-stop-list" title="Permalink to this headline">¶</a></h4>
<p>The answer to this comes in two parts. First, compiling various <strong>stop lists</strong> has been an ongoing research area in
natural language processing (NLP) since the emergence of information retrieval in the 1950s. There are a few
popular ones, like the Buckley-Salton list or the Brown list, which capture many of the words we’d think to remove:
“the,” “do,” “as,” etc. Popular NLP packages like <code class="docutils literal notranslate"><span class="pre">nltk</span></code> and <code class="docutils literal notranslate"><span class="pre">gensim</span></code> even come preloaded with generalized lists,
which you can quickly load.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">gensim.parsing.preprocessing</span> <span class="kn">import</span> <span class="n">STOPWORDS</span>

<span class="n">nltk_stopwords</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
<span class="n">gensim_stopwords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">STOPWORDS</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Number of entries in `ntlk` stop list:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">nltk_stopwords</span><span class="p">),</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Number of entries in `gensim` stop list:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">gensim_stopwords</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of entries in `ntlk` stop list: 179 
Number of entries in `gensim` stop list: 337
</pre></div>
</div>
</div>
</div>
<p>There are, however, substantial differences between stop lists, and you should carefully consider what they contain. Consider, for example, some of the stranger entries in the <code class="docutils literal notranslate"><span class="pre">gensim</span></code> stop list. While it contains the usual
suspects:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;do&#39;</span><span class="p">,</span> <span class="s1">&#39;and&#39;</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">word</span><span class="si">:</span><span class="s2">&lt;3</span><span class="si">}</span><span class="s2"> in `gensim` stop list: </span><span class="si">{</span><span class="n">word</span> <span class="ow">in</span> <span class="n">gensim_stopwords</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>the in `gensim` stop list: True
do  in `gensim` stop list: True
and in `gensim` stop list: True
</pre></div>
</div>
</div>
</div>
<p>…it also contains words like “computer,” “empty,” and “thick”:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;computer&#39;</span><span class="p">,</span> <span class="s1">&#39;empty&#39;</span><span class="p">,</span> <span class="s1">&#39;thick&#39;</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">word</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2"> in `gensim` stop list: </span><span class="si">{</span><span class="n">word</span> <span class="ow">in</span> <span class="n">gensim_stopwords</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>computer in `gensim` stop list: True
empty    in `gensim` stop list: True
thick    in `gensim` stop list: True
</pre></div>
</div>
</div>
</div>
<p>“Computer” isn’t likely to turn up in <em>Frankenstein</em>, but “thick” comes up several times in the novel. We can see
these instances if we return to <code class="docutils literal notranslate"><span class="pre">cleaned</span></code>, which stores the novel in a list:</p>
<div class="margin sidebar">
<p class="sidebar-title">What we’re doing here:</p>
<p>First, use list comprehension to find the index positions of every instance of “thick.”</p>
<p>Then, for each of those index positions:</p>
<ul class="simple">
<li><p>Get the two words before the index (<code class="docutils literal notranslate"><span class="pre">start_span</span></code>) and the two words after it (<code class="docutils literal notranslate"><span class="pre">end_span</span></code>)</p></li>
<li><p>Index <code class="docutils literal notranslate"><span class="pre">cleaned</span></code> with those start and end points</p></li>
<li><p>Join the indexed selection into a string and print</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">idx_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span> <span class="k">if</span> <span class="n">word</span> <span class="o">==</span> <span class="s1">&#39;thick&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idx_list</span><span class="p">:</span>
    <span class="n">start_span</span><span class="p">,</span> <span class="n">end_span</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">3</span>
    <span class="n">span</span> <span class="o">=</span> <span class="n">cleaned</span><span class="p">[</span><span class="n">start_span</span> <span class="p">:</span> <span class="n">end_span</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">idx</span><span class="si">:</span><span class="s2">&gt;5</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">span</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 2902 a very thick fog we
10157 into the thick of life
29042 torrents and thick mists hid
29370 curling in thick wreaths around
36291 with a thick black veil
43328 in some thick underwood determining
56000 by a thick cloud and
</pre></div>
</div>
</div>
</div>
<p>This output brings us to the second, and more important part of the answer from above: <strong>removing stop words
depends on your texts and your research question(s)</strong>. We’re looking at a novel – and a gothic novel at that. The
kinds of questions we could ask about this novel might have to do with <em>tone</em> or <em>style</em>, <em>word choice</em>, even
<em>description</em>. In that sense, we definitely want to hold on to words like “thick” and “empty.” But in other texts,
or with other research questions, that might not be the case. A good stop list, then, is application-specific; you
may in fact find yourself adding <em>additional</em> words to stop lists, depending on what you’re analyzing.</p>
<p>That all said, there are a broad set of NLP tasks that can really depend on keeping stop words in your text. These are tasks that fall under what’s called <strong>part-of-speech</strong> tagging: they rely on stop words to parse the
grammatical structure of text. Below, we will discuss one such example of these tasks, though for now, we’ll go
ahead with a stop list to demonstrate the result.</p>
<p>For our purposes, the more conservative <code class="docutils literal notranslate"><span class="pre">nltk</span></code> list will suffice. Note that it’s also customary to remove any
two-character words when we’re applying stop words (this prevents us from seeing things like “st,” or street). We
will save the result of stopping out this list’s words in a new variable, <code class="docutils literal notranslate"><span class="pre">stopped_counts</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">to_remove</span> <span class="o">=</span> <span class="n">cleaned_counts</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">nltk_stopwords</span><span class="p">)</span>
<span class="n">stopped_counts</span> <span class="o">=</span> <span class="n">cleaned_counts</span><span class="p">[</span><span class="o">~</span><span class="n">to_remove</span><span class="p">]</span>
<span class="n">stopped_counts</span> <span class="o">=</span> <span class="n">stopped_counts</span><span class="p">[</span><span class="n">stopped_counts</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Because we were already working in <code class="docutils literal notranslate"><span class="pre">Pandas</span></code>, we’re using a series subset to do this, but you could just as easily
remove stop words with list comprehension. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">cleaned</span> <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">nltk_stopwords</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<p>With our stop words removed, let’s look at our total counts and then make another count plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of unique words after applying `nltk` stop words:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stopped_counts</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of unique words after applying `nltk` stop words: 6848
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_counts</span><span class="p">(</span><span class="n">stopped_counts</span><span class="p">,</span> <span class="n">n_words</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">label_sample</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/03_cleaning-and-counting_56_0.png" src="_images/03_cleaning-and-counting_56_0.png" />
</div>
</div>
</div>
<div class="section" id="iteratively-building-stop-lists">
<h4><span class="section-number">3.1.5.3. </span>Iteratively building stop lists<a class="headerlink" href="#iteratively-building-stop-lists" title="Permalink to this headline">¶</a></h4>
<p>This is better, though there are still some words like “one” and “yet” that it would be best to remove. The list
provided by <code class="docutils literal notranslate"><span class="pre">nltk</span></code> is good, but it’s a little <em>too</em> conservative, so we’ll want to modify it. This is perfectly
normal: like removing punctuation, getting a stop list just right is an iterative process that takes multiple
tries.</p>
<p>To the <code class="docutils literal notranslate"><span class="pre">nltk</span></code> list, we’ll add a set of stop words compiled by the developers of <a class="reference external" href="https://www.voyant-tools.org/">Voyant</a>, a text analysis portal.
We can combine the two with a set union…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/voyant_stoplist.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">voyant_stopwords</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
<span class="n">custom_stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">nltk_stopwords</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">voyant_stopwords</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>…refilter our counts series…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">to_remove</span> <span class="o">=</span> <span class="n">cleaned_counts</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">custom_stopwords</span><span class="p">)</span>
<span class="n">stopped_counts</span> <span class="o">=</span> <span class="n">cleaned_counts</span><span class="p">[</span><span class="o">~</span><span class="n">to_remove</span><span class="p">]</span>
<span class="n">stopped_counts</span> <span class="o">=</span> <span class="n">stopped_counts</span><span class="p">[</span><span class="n">stopped_counts</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of unique words after applying custom stop words:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stopped_counts</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of unique words after applying custom stop words: 6717
</pre></div>
</div>
</div>
</div>
<p>…and plot the results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_counts</span><span class="p">(</span><span class="n">stopped_counts</span><span class="p">,</span> <span class="n">n_words</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">label_sample</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/03_cleaning-and-counting_62_0.png" src="_images/03_cleaning-and-counting_62_0.png" />
</div>
</div>
<p>Notice how, in each iteration through these stop lists, more and more “meaningful” words appear in our plot. From
our current vantage, there seems to be much more we could learn about the specifics of <em>Frankenstein</em> as a novel by
examining words like “feelings,” “nature,” and “countenance,” than if we stuck with “the,” “of,” and “to.”</p>
<p>We’ll quickly glance at the top 10 words in our unstopped text and our stopped text to see such differences more
clearly. Here’s unstopped:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cleaned_counts</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;COUNT&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>COUNT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>the</th>
      <td>4194</td>
    </tr>
    <tr>
      <th>and</th>
      <td>2976</td>
    </tr>
    <tr>
      <th>i</th>
      <td>2850</td>
    </tr>
    <tr>
      <th>of</th>
      <td>2642</td>
    </tr>
    <tr>
      <th>to</th>
      <td>2094</td>
    </tr>
    <tr>
      <th>my</th>
      <td>1776</td>
    </tr>
    <tr>
      <th>a</th>
      <td>1391</td>
    </tr>
    <tr>
      <th>in</th>
      <td>1129</td>
    </tr>
    <tr>
      <th>was</th>
      <td>1021</td>
    </tr>
    <tr>
      <th>that</th>
      <td>1017</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>And here’s stopped:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">stopped_counts</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;COUNT&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>COUNT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>man</th>
      <td>132</td>
    </tr>
    <tr>
      <th>life</th>
      <td>115</td>
    </tr>
    <tr>
      <th>father</th>
      <td>113</td>
    </tr>
    <tr>
      <th>shall</th>
      <td>105</td>
    </tr>
    <tr>
      <th>eyes</th>
      <td>104</td>
    </tr>
    <tr>
      <th>said</th>
      <td>102</td>
    </tr>
    <tr>
      <th>time</th>
      <td>98</td>
    </tr>
    <tr>
      <th>saw</th>
      <td>94</td>
    </tr>
    <tr>
      <th>night</th>
      <td>92</td>
    </tr>
    <tr>
      <th>elizabeth</th>
      <td>88</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
</div>
<div class="section" id="text-cleaning-advanced">
<h2><span class="section-number">3.2. </span>Text Cleaning: Advanced<a class="headerlink" href="#text-cleaning-advanced" title="Permalink to this headline">¶</a></h2>
<p>With our stop words removed, we could consider our text cleaning to be complete. But there are two more steps that
we could do to further process our data: stemming and lemmatizing. We’ll consider these separately from the steps
above because they entail making significant changes to our data. Instead of simply removing pieces of irrelevant
information, as with stop word removal, stemming and lemmatizing transform the forms of words.</p>
<div class="section" id="stemming">
<h3><span class="section-number">3.2.1. </span>Stemming<a class="headerlink" href="#stemming" title="Permalink to this headline">¶</a></h3>
<p><strong>Stemming</strong> algorithms are rule-based procedures that reduce words to their root forms. They cut down on the
amount of morphological variance in your corpus, merging plurals into singulars, changing gerunds into static
verbs, etc. This can be useful for a number of reasons. It cuts down on corpus size, which might be necessary when
dealing with a large number of texts, or when building a fast search engine. Stemming also enacts a shift to a
higher, more generalized form of words’ meanings: instead of counting “have” and “having” as two different words
with two different meanings, stemming would enable us to count them as a single entity, “have.”</p>
<p>We can see this if we load the <a class="reference external" href="https://tartarus.org/martin/PorterStemmer/">Porter stemmer</a> from <code class="docutils literal notranslate"><span class="pre">nltk</span></code>. It’s a class object, which we initialize by saving to
a variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.stem.porter</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at a few words.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">to_stem</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;books&#39;</span><span class="p">,</span> <span class="s1">&#39;having&#39;</span><span class="p">,</span> <span class="s1">&#39;running&#39;</span><span class="p">,</span> <span class="s1">&#39;complicated&#39;</span><span class="p">,</span> <span class="s1">&#39;complicity&#39;</span><span class="p">,</span> <span class="s1">&#39;malleability&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">to_stem</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">word</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> =&gt; </span><span class="si">{</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>books        =&gt; book
having       =&gt; have
running      =&gt; run
complicated  =&gt; complic
complicity   =&gt; complic
malleability =&gt; malleabl
</pre></div>
</div>
</div>
</div>
<p>There’s a lot of potential value in enacting these transformations with a stemmer. So far we haven’t developed a
method of handling plurals, which, it could be reasonably argued, should be considered the same as their singular
variants; the stemmer handles this. Likewise, “having” to “have” is a useful transformation, and it would be
difficult to come up with a custom algorithm that could handle the complexities of not only removing a gerund but
replacing it with an <em>e</em>.</p>
<p>That said, the problem with stemming is that the process is rule-based and struggles with certain words. It can
inadvertently merge what should be two separate words, as with “complicated” and “complicity” becoming “complic.”
And more, “complic,” like “malleabl,” isn’t really a word. Rather, it represents a general idea, but one that a)
is too baggy (it merges together two different words); and b) is harder to interpret in later analysis (how would
we know what “complic” means when looking at word count distributions?).</p>
</div>
<div class="section" id="lemmatizing">
<h3><span class="section-number">3.2.2. </span>Lemmatizing<a class="headerlink" href="#lemmatizing" title="Permalink to this headline">¶</a></h3>
<p><strong>Lemmatizing</strong> textual data solves some of these problems, though at the cost of more complexity and more
computational resources. Like stemming, lemmatization removes the inflectional forms of words. While it tends to be
more conservative in its approach, it is better at avoiding lexical merges like “complicated” and “complicity”
becoming “complic.” More, the result of lemmatization is always a fully readable word, so no need to worry about
trying to remember what “malleabl” means. If, say, you want to know something about the <em>theme</em> or <em>topicality</em> of
a text, lemmatization would be a valuable step.</p>
<div class="section" id="part-of-speech-tags-and-dependency-parsing">
<h4><span class="section-number">3.2.2.1. </span>Part-of-speech tags and dependency parsing<a class="headerlink" href="#part-of-speech-tags-and-dependency-parsing" title="Permalink to this headline">¶</a></h4>
<p>Lemmatizers can do all this because they use the context provided by <strong>part-of-speech tags</strong> (POS tags). To get the
best results, you need to pipe in a tag for each word, which the lemmatizer will use to make its decisions. In
principle, this is easy enough to do. There are software libraries, including <code class="docutils literal notranslate"><span class="pre">nltk</span></code>, that will automatically
assign POS tags through a process called <strong>dependency parsing</strong>. This proces analyzes the grammatical structure of
a text string and tags words accordingly.</p>
<p>But now for the catch: to work at their best, <em>dependency parsers require both stop words and some punctuation
marks</em>. Because of this, if you know you want to lemmatize your text, you’re going to have to tag your text before
doing other steps in the text cleaning process. Further, it’s better to let an automatic tokenizer handle which
pieces of punctuation to leave in and which ones to leave out. You’ll still need to remove everything later on, but
only after the dependency parser has done its work. The revised text cleaning steps would look like this:</p>
<ol class="simple">
<li><p>Tokenize</p></li>
<li><p>Assign POS tags</p></li>
<li><p>Resolve word casing</p></li>
<li><p>Remove punctuation</p></li>
<li><p>Remove numbers</p></li>
<li><p>Remove extra whitespaces</p></li>
<li><p>Remove stopwords</p></li>
<li><p>Lemmatize</p></li>
</ol>
</div>
<div class="section" id="sample-lemmatization-workflow">
<h4><span class="section-number">3.2.2.2. </span>Sample lemmatization workflow<a class="headerlink" href="#sample-lemmatization-workflow" title="Permalink to this headline">¶</a></h4>
<p>We won’t do all of this for <em>Frankenstein</em>, but in the next session, when we start to use classification models to
understand the differences between texts, we will. For now, we’ll demonstrate an example of POS tagging using the
<code class="docutils literal notranslate"><span class="pre">nltk</span></code> tokenizer in concert with its lemmatizer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">wordnet</span>

<span class="n">sample_string</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">The strong coffee, which I had after lunch, was $3. It kept me going the rest of the day.</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">tokenized</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;String after `nltk` tokenization:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>String after `nltk` tokenization:

The
strong
coffee
,
which
I
had
after
lunch
,
was
$
3
.
It
kept
me
going
the
rest
of
the
day
.
</pre></div>
</div>
</div>
</div>
<p>Assigning POS tags:</p>
<div class="margin sidebar">
<p class="sidebar-title">What does each tag mean?</p>
<p><code class="docutils literal notranslate"><span class="pre">nltk</span></code> uses the Penn TreeBank tags, which you can find <a class="reference external" href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html">here</a>. If the tagger receives a punctuation mark that isn’t
one of its special cases (“.” or “$”, for example), it simply repeats that mark.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tagged</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">tokenized</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tagged tokens:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">tagged</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tagged tokens:

(&#39;The&#39;, &#39;DT&#39;)
(&#39;strong&#39;, &#39;JJ&#39;)
(&#39;coffee&#39;, &#39;NN&#39;)
(&#39;,&#39;, &#39;,&#39;)
(&#39;which&#39;, &#39;WDT&#39;)
(&#39;I&#39;, &#39;PRP&#39;)
(&#39;had&#39;, &#39;VBD&#39;)
(&#39;after&#39;, &#39;IN&#39;)
(&#39;lunch&#39;, &#39;NN&#39;)
(&#39;,&#39;, &#39;,&#39;)
(&#39;was&#39;, &#39;VBD&#39;)
(&#39;$&#39;, &#39;$&#39;)
(&#39;3&#39;, &#39;CD&#39;)
(&#39;.&#39;, &#39;.&#39;)
(&#39;It&#39;, &#39;PRP&#39;)
(&#39;kept&#39;, &#39;VBD&#39;)
(&#39;me&#39;, &#39;PRP&#39;)
(&#39;going&#39;, &#39;VBG&#39;)
(&#39;the&#39;, &#39;DT&#39;)
(&#39;rest&#39;, &#39;NN&#39;)
(&#39;of&#39;, &#39;IN&#39;)
(&#39;the&#39;, &#39;DT&#39;)
(&#39;day&#39;, &#39;NN&#39;)
(&#39;.&#39;, &#39;.&#39;)
</pre></div>
</div>
</div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">nltk.pos_tag()</span></code> returns a list of tuples. We’ll put these in a dataframe and clean that way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tagged</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tagged</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WORD&#39;</span><span class="p">,</span> <span class="s1">&#39;TAG&#39;</span><span class="p">])</span>
<span class="n">tagged</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WORD</th>
      <th>TAG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The</td>
      <td>DT</td>
    </tr>
    <tr>
      <th>1</th>
      <td>strong</td>
      <td>JJ</td>
    </tr>
    <tr>
      <th>2</th>
      <td>coffee</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>,</td>
      <td>,</td>
    </tr>
    <tr>
      <th>4</th>
      <td>which</td>
      <td>WDT</td>
    </tr>
    <tr>
      <th>5</th>
      <td>I</td>
      <td>PRP</td>
    </tr>
    <tr>
      <th>6</th>
      <td>had</td>
      <td>VBD</td>
    </tr>
    <tr>
      <th>7</th>
      <td>after</td>
      <td>IN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>lunch</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>9</th>
      <td>,</td>
      <td>,</td>
    </tr>
    <tr>
      <th>10</th>
      <td>was</td>
      <td>VBD</td>
    </tr>
    <tr>
      <th>11</th>
      <td>$</td>
      <td>$</td>
    </tr>
    <tr>
      <th>12</th>
      <td>3</td>
      <td>CD</td>
    </tr>
    <tr>
      <th>13</th>
      <td>.</td>
      <td>.</td>
    </tr>
    <tr>
      <th>14</th>
      <td>It</td>
      <td>PRP</td>
    </tr>
    <tr>
      <th>15</th>
      <td>kept</td>
      <td>VBD</td>
    </tr>
    <tr>
      <th>16</th>
      <td>me</td>
      <td>PRP</td>
    </tr>
    <tr>
      <th>17</th>
      <td>going</td>
      <td>VBG</td>
    </tr>
    <tr>
      <th>18</th>
      <td>the</td>
      <td>DT</td>
    </tr>
    <tr>
      <th>19</th>
      <td>rest</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>20</th>
      <td>of</td>
      <td>IN</td>
    </tr>
    <tr>
      <th>21</th>
      <td>the</td>
      <td>DT</td>
    </tr>
    <tr>
      <th>22</th>
      <td>day</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>23</th>
      <td>.</td>
      <td>.</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="margin sidebar">
<p class="sidebar-title">Steps:</p>
<ol class="simple">
<li><p>Reassign lowercase versions of all words</p></li>
<li><p>Subset <code class="docutils literal notranslate"><span class="pre">tagged</span></code> for all entries that aren’t “,”, “$”, or “.”</p></li>
<li><p>Subset <code class="docutils literal notranslate"><span class="pre">tagged</span></code> for all non-numeric numbers</p></li>
<li><p>Subset <code class="docutils literal notranslate"><span class="pre">tagged</span></code> for words not in stop words</p></li>
</ol>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tagged</span> <span class="o">=</span> <span class="n">tagged</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">WORD</span> <span class="o">=</span> <span class="n">tagged</span><span class="p">[</span><span class="s1">&#39;WORD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="n">tagged</span> <span class="o">=</span> <span class="n">tagged</span><span class="p">[</span><span class="o">~</span><span class="n">tagged</span><span class="p">[</span><span class="s1">&#39;WORD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="s2">&quot;$&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">])]</span>
<span class="n">tagged</span> <span class="o">=</span> <span class="n">tagged</span><span class="p">[</span><span class="n">tagged</span><span class="p">[</span><span class="s1">&#39;WORD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()]</span>
<span class="n">tagged</span> <span class="o">=</span> <span class="n">tagged</span><span class="p">[</span><span class="o">~</span><span class="n">tagged</span><span class="p">[</span><span class="s1">&#39;WORD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">custom_stopwords</span><span class="p">)]</span>
<span class="n">tagged</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WORD</th>
      <th>TAG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>strong</td>
      <td>JJ</td>
    </tr>
    <tr>
      <th>2</th>
      <td>coffee</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>lunch</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>15</th>
      <td>kept</td>
      <td>VBD</td>
    </tr>
    <tr>
      <th>17</th>
      <td>going</td>
      <td>VBG</td>
    </tr>
    <tr>
      <th>19</th>
      <td>rest</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>22</th>
      <td>day</td>
      <td>NN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now we can load a lemmatizer – and write a function to handle discrepancies between the tags we have up above and
the tags that this lemmatizer expects. We did say this step is more complicated!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">convert_tag</span><span class="p">(</span><span class="n">tag</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">tag</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;J&#39;</span><span class="p">):</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="n">wordnet</span><span class="o">.</span><span class="n">ADJ</span>
    <span class="k">elif</span> <span class="n">tag</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;V&#39;</span><span class="p">):</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="n">wordnet</span><span class="o">.</span><span class="n">VERB</span>
    <span class="k">elif</span> <span class="n">tag</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;N&#39;</span><span class="p">):</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="n">wordnet</span><span class="o">.</span><span class="n">NOUN</span>
    <span class="k">elif</span> <span class="n">tag</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;R&#39;</span><span class="p">):</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="n">wordnet</span><span class="o">.</span><span class="n">ADV</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">return</span> <span class="n">tag</span>

<span class="n">tagged</span> <span class="o">=</span> <span class="n">tagged</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">NEW_TAG</span> <span class="o">=</span> <span class="n">tagged</span><span class="p">[</span><span class="s1">&#39;TAG&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">convert_tag</span><span class="p">))</span>
<span class="n">tagged</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WORD</th>
      <th>TAG</th>
      <th>NEW_TAG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>strong</td>
      <td>JJ</td>
      <td>a</td>
    </tr>
    <tr>
      <th>2</th>
      <td>coffee</td>
      <td>NN</td>
      <td>n</td>
    </tr>
    <tr>
      <th>8</th>
      <td>lunch</td>
      <td>NN</td>
      <td>n</td>
    </tr>
    <tr>
      <th>15</th>
      <td>kept</td>
      <td>VBD</td>
      <td>v</td>
    </tr>
    <tr>
      <th>17</th>
      <td>going</td>
      <td>VBG</td>
      <td>v</td>
    </tr>
    <tr>
      <th>19</th>
      <td>rest</td>
      <td>NN</td>
      <td>n</td>
    </tr>
    <tr>
      <th>22</th>
      <td>day</td>
      <td>NN</td>
      <td>n</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Finally, we can lemmatize.</p>
<div class="margin sidebar">
<p class="sidebar-title">A bit of error handling</p>
<p>In case our tagger fails to assign tag, we can just send the word to our lemmatizer. The lemmatizer may have this
word stored in its database, in which case it will make a change based on that. Otherwise, it just returns the
word.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lemmatize_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">new_tag</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">new_tag</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
        <span class="n">lemma</span> <span class="o">=</span> <span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="n">new_tag</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lemma</span> <span class="o">=</span> <span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lemma</span>

<span class="n">tagged</span> <span class="o">=</span> <span class="n">tagged</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">LEMMATIZED</span> <span class="o">=</span> <span class="n">tagged</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">lemmatize_word</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;WORD&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;NEW_TAG&#39;</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">tagged</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WORD</th>
      <th>TAG</th>
      <th>NEW_TAG</th>
      <th>LEMMATIZED</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>strong</td>
      <td>JJ</td>
      <td>a</td>
      <td>strong</td>
    </tr>
    <tr>
      <th>2</th>
      <td>coffee</td>
      <td>NN</td>
      <td>n</td>
      <td>coffee</td>
    </tr>
    <tr>
      <th>8</th>
      <td>lunch</td>
      <td>NN</td>
      <td>n</td>
      <td>lunch</td>
    </tr>
    <tr>
      <th>15</th>
      <td>kept</td>
      <td>VBD</td>
      <td>v</td>
      <td>keep</td>
    </tr>
    <tr>
      <th>17</th>
      <td>going</td>
      <td>VBG</td>
      <td>v</td>
      <td>go</td>
    </tr>
    <tr>
      <th>19</th>
      <td>rest</td>
      <td>NN</td>
      <td>n</td>
      <td>rest</td>
    </tr>
    <tr>
      <th>22</th>
      <td>day</td>
      <td>NN</td>
      <td>n</td>
      <td>day</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>This is a lot of work, but it does preserve important distinctions between words:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">complic_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;complicated&#39;</span><span class="p">:</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="s1">&#39;complicity&#39;</span><span class="p">:</span> <span class="s1">&#39;n&#39;</span><span class="p">}</span>

<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">complic_dict</span><span class="p">:</span>
    <span class="n">word</span><span class="p">,</span> <span class="n">tag</span> <span class="o">=</span> <span class="n">word</span><span class="p">,</span> <span class="n">complic_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="n">lemma</span> <span class="o">=</span> <span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="n">tag</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">word</span><span class="si">:</span><span class="s2">&lt;11</span><span class="si">}</span><span class="s2"> =&gt; </span><span class="si">{</span><span class="n">lemma</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>complicated =&gt; complicate
complicity  =&gt; complicity
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="chunking-with-n-grams">
<h2><span class="section-number">3.3. </span>Chunking with N-Grams<a class="headerlink" href="#chunking-with-n-grams" title="Permalink to this headline">¶</a></h2>
<p>With that, we are now done cleaning text. The last thing we’ll discuss in this session is <strong>chunking</strong>. Chunking is
closely related to tokenization. It involves breaking text into multi-token spans. This is useful if, for example,
we want to find phrases in our data, or even entities. To wit: the processes above would dissolve “New York” into
two separate tokens, and it would be very difficult to know how to reattach “new” and “york” from something like
raw count metrics – we may not even know this entity exists in the first place. Chunking, on the other hand, would
lead us to identify it.</p>
<p>In this sense, it’s often useful to count not only single words in our text, but continuous two word strings, even
three. We call these strings <strong>n-grams</strong>, where <em>n</em> is the number of tokens with which we chunk. “Bigrams” are
two-token chunks. “Trigrams” are three-token chunks. Then, there are “4-grams,” “5-grams,” and so on. Technically,
there’s no real limit to the size of your n-grams, though their usefulness will depend on your data and your
research questions.</p>
<p>To finish this chapter, we’ll produce bigram counts on <em>Frankenstein</em>.</p>
<p>First, we’ll return to <code class="docutils literal notranslate"><span class="pre">cleaned</span></code>, which holds the entire text in its original form:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;letter&#39;,
 &#39;to&#39;,
 &#39;mrs&#39;,
 &#39;saville&#39;,
 &#39;england&#39;,
 &#39;st&#39;,
 &#39;petersburgh&#39;,
 &#39;dec&#39;,
 &#39;th&#39;,
 &#39;you&#39;]
</pre></div>
</div>
</div>
</div>
<p>As before, let’s load this into a series. Remember too that, while <code class="docutils literal notranslate"><span class="pre">cleaned</span></code> no longer contains punctuation,
numbers, and extra whitespaces, it still contains stop words. We’ll need to filter them out.</p>
<div class="margin sidebar">
<p class="sidebar-title">Note:</p>
<p>Unlike in the code above, we do not need to use <code class="docutils literal notranslate"><span class="pre">.index</span></code> on our series because our words are stored in the series’
values.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleaned</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>

<span class="n">to_remove</span> <span class="o">=</span> <span class="n">cleaned</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">custom_stopwords</span><span class="p">)</span>
<span class="n">stopped</span> <span class="o">=</span> <span class="n">cleaned</span><span class="p">[</span><span class="o">~</span><span class="n">to_remove</span><span class="p">]</span>
<span class="n">stopped</span> <span class="o">=</span> <span class="n">stopped</span><span class="p">[</span><span class="n">stopped</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">stopped</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0          letter
2             mrs
3         saville
4         england
6     petersburgh
7             dec
11        rejoice
13           hear
16       disaster
18    accompanied
dtype: object
</pre></div>
</div>
</div>
</div>
<p>Once again, <code class="docutils literal notranslate"><span class="pre">nltk</span></code> has in-built functionality to help us with our chunking. There are a few options here, but since
we want to get bigram counts, we’ll use objects from <code class="docutils literal notranslate"><span class="pre">nltk</span></code>’s <code class="docutils literal notranslate"><span class="pre">collocations</span></code> module. <code class="docutils literal notranslate"><span class="pre">BigramAssocMeasures()</span></code> will
generate our scores, while <code class="docutils literal notranslate"><span class="pre">BigramCollocationFinder()</span></code> will create our bigrams.</p>
<div class="margin sidebar">
<p class="sidebar-title">Other options</p>
<p><code class="docutils literal notranslate"><span class="pre">nltk</span></code> also has a <code class="docutils literal notranslate"><span class="pre">bigrams()</span></code> object that you can call with <code class="docutils literal notranslate"><span class="pre">nltk.bigrams()</span></code>. It returns an iterator of all
bigrams, which is quite useful. That said, it’s harder to use this object to produce valuable bigram metrics, as
we’ll do below.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">collocations</span>

<span class="n">bigram_measures</span> <span class="o">=</span> <span class="n">collocations</span><span class="o">.</span><span class="n">BigramAssocMeasures</span><span class="p">()</span>
<span class="n">bigram_finder</span> <span class="o">=</span> <span class="n">collocations</span><span class="o">.</span><span class="n">BigramCollocationFinder</span><span class="o">.</span><span class="n">from_words</span><span class="p">(</span><span class="n">stopped</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If we want to get the raw bigram counts (which <code class="docutils literal notranslate"><span class="pre">nltk</span></code> calls a “frequency distribution”), we use the <code class="docutils literal notranslate"><span class="pre">ngram_fd</span></code>
method. That can be stored in a dataframe, which we’ll sort by value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">freq</span> <span class="o">=</span> <span class="n">bigram_finder</span><span class="o">.</span><span class="n">ngram_fd</span>

<span class="n">bigram_freq</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">freq</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WORD&#39;</span><span class="p">,</span> <span class="s1">&#39;PAIR&#39;</span><span class="p">])</span>
<span class="n">bigram_freq</span> <span class="o">=</span> <span class="n">bigram_freq</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;WORD&#39;</span><span class="p">)</span>
<span class="n">bigram_freq</span> <span class="o">=</span> <span class="n">bigram_freq</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">VALUE</span> <span class="o">=</span> <span class="n">freq</span><span class="o">.</span><span class="n">values</span><span class="p">())</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;VALUE&#39;</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

<span class="n">bigram_freq</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PAIR</th>
      <th>VALUE</th>
    </tr>
    <tr>
      <th>WORD</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>old</th>
      <td>man</td>
      <td>32</td>
    </tr>
    <tr>
      <th>native</th>
      <td>country</td>
      <td>15</td>
    </tr>
    <tr>
      <th>natural</th>
      <td>philosophy</td>
      <td>14</td>
    </tr>
    <tr>
      <th>taken</th>
      <td>place</td>
      <td>13</td>
    </tr>
    <tr>
      <th>fellow</th>
      <td>creatures</td>
      <td>12</td>
    </tr>
    <tr>
      <th>dear</th>
      <td>victor</td>
      <td>10</td>
    </tr>
    <tr>
      <th>young</th>
      <td>man</td>
      <td>9</td>
    </tr>
    <tr>
      <th>short</th>
      <td>time</td>
      <td>9</td>
    </tr>
    <tr>
      <th>long</th>
      <td>time</td>
      <td>9</td>
    </tr>
    <tr>
      <th>life</th>
      <td>death</td>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Looks good! We can see some phrases peeking through. But while bigram counts provide us with information about
frequently occuring phrases in our text, it’s hard to know how <em>unique</em> these phrases are. For example: “man”
appears throughout the text, so it’s likely to appear in a lot of bigrams; indeed, we can even see it appearing
again in “young man.” How, then, might we determine whether there’s something unique about whether “old” and “man”
consistently stick together?</p>
<p>One way we can do this is with a PMI, or <strong>pointwise mutual information</strong>, score. PMI measures the association
strength of a pair of outcomes. In our case, the higher the score, the more likely a given bigram pair will be with
respect to the other bigrams in which the two words of the present one appear.</p>
<p>We can get a PMI score for each bigram using the <code class="docutils literal notranslate"><span class="pre">score_ngrams</span></code> and <code class="docutils literal notranslate"><span class="pre">pmi</span></code> methods of our collocator and measurer,
respectively. This will return a list of nested tuples, which will take a little work to coerce into a dataframe.</p>
<div class="margin sidebar">
<p class="sidebar-title">Steps:</p>
<ol class="simple">
<li><p>Make our dataframe; the result stores a tuple in the <code class="docutils literal notranslate"><span class="pre">BIGRAMS</span></code> column</p></li>
<li><p>Assign the first position of each tuple in <code class="docutils literal notranslate"><span class="pre">BIGRAMS</span></code> to <code class="docutils literal notranslate"><span class="pre">WORD</span></code></p></li>
<li><p>Assign the second position of each tuple in <code class="docutils literal notranslate"><span class="pre">BIGRAMS</span></code> to <code class="docutils literal notranslate"><span class="pre">PAIR</span></code></p></li>
<li><p>Remove <code class="docutils literal notranslate"><span class="pre">BIGRAMS</span></code></p></li>
<li><p>Rearrange our columns</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">WORDS</span></code> as our index</p></li>
</ol>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bigram_pmi</span> <span class="o">=</span> <span class="n">bigram_finder</span><span class="o">.</span><span class="n">score_ngrams</span><span class="p">(</span><span class="n">bigram_measures</span><span class="o">.</span><span class="n">pmi</span><span class="p">)</span>

<span class="n">pmi_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">bigram_pmi</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BIGRAMS&#39;</span><span class="p">,</span> <span class="s1">&#39;PMI&#39;</span><span class="p">])</span>
<span class="n">pmi_df</span> <span class="o">=</span> <span class="n">pmi_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">WORD</span> <span class="o">=</span> <span class="n">pmi_df</span><span class="p">[</span><span class="s1">&#39;BIGRAMS&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
    <span class="n">PAIR</span> <span class="o">=</span> <span class="n">pmi_df</span><span class="p">[</span><span class="s1">&#39;BIGRAMS&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="p">)</span>

<span class="n">pmi_df</span> <span class="o">=</span> <span class="n">pmi_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BIGRAMS&#39;</span><span class="p">])</span>
<span class="n">pmi_df</span> <span class="o">=</span> <span class="n">pmi_df</span><span class="p">[[</span><span class="s1">&#39;WORD&#39;</span><span class="p">,</span> <span class="s1">&#39;PAIR&#39;</span><span class="p">,</span> <span class="s1">&#39;PMI&#39;</span><span class="p">]]</span>
<span class="n">pmi_df</span> <span class="o">=</span> <span class="n">pmi_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;WORD&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a quick look at the distribution of these scores.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmi_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PMI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>29053.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>8.473590</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.608898</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.029961</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>6.572605</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>8.402680</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>10.309571</td>
    </tr>
    <tr>
      <th>max</th>
      <td>14.894534</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here are the 10 bottom-most scoring bigrams:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmi_df</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PAIR</th>
      <th>PMI</th>
    </tr>
    <tr>
      <th>WORD</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>said</th>
      <td>father</td>
      <td>1.401929</td>
    </tr>
    <tr>
      <th>man</th>
      <td>saw</td>
      <td>1.295551</td>
    </tr>
    <tr>
      <th>saw</th>
      <td>man</td>
      <td>1.295551</td>
    </tr>
    <tr>
      <th>father</th>
      <td>father</td>
      <td>1.254176</td>
    </tr>
    <tr>
      <th>life</th>
      <td>father</td>
      <td>1.228865</td>
    </tr>
    <tr>
      <th>said</th>
      <td>man</td>
      <td>1.177714</td>
    </tr>
    <tr>
      <th>man</th>
      <td>eyes</td>
      <td>1.149700</td>
    </tr>
    <tr>
      <th>man</th>
      <td>shall</td>
      <td>1.135894</td>
    </tr>
    <tr>
      <th>shall</th>
      <td>man</td>
      <td>1.135894</td>
    </tr>
    <tr>
      <th>man</th>
      <td>father</td>
      <td>1.029961</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>And here’s a sampling of 25 bigrams with a PMI above 10.31 (bigrams above the 75th percentile):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmi_df</span><span class="p">[</span><span class="n">pmi_df</span><span class="p">[</span><span class="s1">&#39;PMI&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">10.31</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;PMI&#39;</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PAIR</th>
      <th>PMI</th>
    </tr>
    <tr>
      <th>WORD</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>advocate</th>
      <td>stated</td>
      <td>14.894534</td>
    </tr>
    <tr>
      <th>naval</th>
      <td>adventurer</td>
      <td>14.894534</td>
    </tr>
    <tr>
      <th>mechanics</th>
      <td>encouraged</td>
      <td>13.894534</td>
    </tr>
    <tr>
      <th>yesterday</th>
      <td>neer</td>
      <td>12.894534</td>
    </tr>
    <tr>
      <th>seashore</th>
      <td>inquired</td>
      <td>12.572605</td>
    </tr>
    <tr>
      <th>commences</th>
      <td>rude</td>
      <td>12.309571</td>
    </tr>
    <tr>
      <th>sensitiveness</th>
      <td>pulse</td>
      <td>12.309571</td>
    </tr>
    <tr>
      <th>mortal</th>
      <td>strife</td>
      <td>12.087179</td>
    </tr>
    <tr>
      <th>desirous</th>
      <td>engage</td>
      <td>11.724609</td>
    </tr>
    <tr>
      <th>situation</th>
      <td>released</td>
      <td>11.572605</td>
    </tr>
    <tr>
      <th>proceeding</th>
      <td>succeed</td>
      <td>11.309571</td>
    </tr>
    <tr>
      <th>diligence</th>
      <td>journal</td>
      <td>11.309571</td>
    </tr>
    <tr>
      <th>retire</th>
      <td>inaccessible</td>
      <td>11.309571</td>
    </tr>
    <tr>
      <th>nights</th>
      <td>guessed</td>
      <td>11.309571</td>
    </tr>
    <tr>
      <th>idol</th>
      <td>better</td>
      <td>11.194094</td>
    </tr>
    <tr>
      <th>incredible</th>
      <td>toil</td>
      <td>11.087179</td>
    </tr>
    <tr>
      <th>scaffold</th>
      <td>survive</td>
      <td>10.987643</td>
    </tr>
    <tr>
      <th>unacquainted</th>
      <td>towns</td>
      <td>10.894534</td>
    </tr>
    <tr>
      <th>advantages</th>
      <td>daily</td>
      <td>10.894534</td>
    </tr>
    <tr>
      <th>floated</th>
      <td>situation</td>
      <td>10.572605</td>
    </tr>
    <tr>
      <th>blind</th>
      <td>vacancy</td>
      <td>10.572605</td>
    </tr>
    <tr>
      <th>proof</th>
      <td>fact</td>
      <td>10.572605</td>
    </tr>
    <tr>
      <th>disciple</th>
      <td>application</td>
      <td>10.502216</td>
    </tr>
    <tr>
      <th>enter</th>
      <td>masquerades</td>
      <td>10.502216</td>
    </tr>
    <tr>
      <th>dead</th>
      <td>hare</td>
      <td>10.370972</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Among the worst-scoring bigrams, we see words that are likely to be combined with many different words: “said,”
“man,” “shall,” etc. On the other hand, among the best-scoring bigrams, we see coherent entities and suggestive
pairings. The latter especially begin to sketch out the specific qualities of Shelley’s prose style.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "nlp"
        },
        kernelOptions: {
            kernelName: "nlp",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'nlp'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="02_from-text-to-data.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">2. </span>From Text to Data</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="04_corpus-analytics.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">4. </span>Corpus Analytics</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Tyler Shoemaker and Carl Stahmer<br/>
        
          <div class="extra_footer">
            <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">
  <img alt="CC BY-SA 4.0" src="https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg"> 
</a>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>