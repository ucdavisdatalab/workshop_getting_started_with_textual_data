
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Corpus Analytics &#8212; Getting Started with Textual Data</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="3. Cleaning and Counting" href="03_cleaning-and-counting.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/datalab-logo-full-color-rgb.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Getting Started with Textual Data</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Overview
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_logistics.html">
   1. Logistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_from-text-to-data.html">
   2. From Text to Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_cleaning-and-counting.html">
   3. Cleaning and Counting
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Corpus Analytics
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/04_corpus-analytics.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ucdavisdatalab/workshop_getting_started_with_textual_data"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ucdavisdatalab/workshop_getting_started_with_textual_data/master?urlpath=tree/04_corpus-analytics.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-a-file-manifest">
   4.1. Using a File Manifest
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-cleaning">
   4.2. Text Cleaning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recap">
     4.2.1. Recap
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-cleaning-functions">
     4.2.2. Text cleaning functions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cleaning-our-texts">
     4.2.3. Cleaning our texts
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-document-term-matrix">
   4.3. The Document-Term Matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyzing-the-corpus">
   4.4. Analyzing the Corpus
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#raw-metrics-documents">
     4.4.1. Raw Metrics: Documents
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#raw-metrics-terms">
     4.4.2. Raw Metrics: Terms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weighted-metrics-tf-idf-scores">
     4.4.3. Weighted Metrics: tf-idf Scores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-correlations">
     4.4.4. Term Correlations
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="corpus-analytics">
<h1><span class="section-number">4. </span>Corpus Analytics<a class="headerlink" href="#corpus-analytics" title="Permalink to this headline">¶</a></h1>
<p>Now that we’ve overviewed all the steps involved in preparing text for computational analysis, we can begin the
work of analysis proper. Whereas the last chapter suggested a few ways we might do this with a single novel, this
one will build out to a whole collection of texts, or a <strong>corpus</strong>. Computational analysis can help us discover
many interesting things about a single text, but looking at this text in the context of many others will do much to
clarify and expand any potential findings we might make. Accordingly, we’ll learn how to implement our cleaning
steps on multiple files and then format them in a way that enables us to make connections between them. We’ll then
generate several metrics about these texts and use them to observe similarities/differences across the corpus.</p>
<p>We’ll also leave <em>Frankenstein</em> behind, at least for now. In place of this novel, we will use Andrew Piper’s
<a class="reference external" href="https://doi.org/10.6084/m9.figshare.17425571.v1">collection of English short stories</a>, which gathers together 50
stories from 1981 to 2006. <strong>UNCLEAR WHETHER WE’LL ULTIMATELY USE THIS ONE—PLUGGING IT IN TO OUTLINE THE
CHAPTER.</strong></p>
<div class="admonition-learning-objectives admonition">
<p class="admonition-title">Learning Objectives</p>
<p>By the end of this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Develop a workflow for cleaning multiple texts and compiling them into a corpus</p></li>
<li><p>Use a document-term matrix, to represent relationships between texts in a corpus</p></li>
<li><p>Generate metrics about texts in a corpus, including document length, term frequency, lexical diversity, etc.</p></li>
<li><p>Explain the difference between raw term metrics and weighted term scoring (specifically, tf-idf scoring)</p></li>
</ul>
</div>
<div class="section" id="using-a-file-manifest">
<h2><span class="section-number">4.1. </span>Using a File Manifest<a class="headerlink" href="#using-a-file-manifest" title="Permalink to this headline">¶</a></h2>
<p>Before we begin cleaning, let’s load in a file manifest to get a quick overview of what will be in our corpus.
We’ll also use this manifest to sequentially load each file, clean it, and add it to our corpus.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">manifest</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/session_two/manifest.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">manifest</span> <span class="o">=</span> <span class="n">manifest</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;TITLE&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Number of stories:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">manifest</span><span class="p">),</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Number of authors:&quot;</span><span class="p">,</span> <span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;NAME&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">(),</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Columns in the manifest:&quot;</span><span class="p">,</span> <span class="n">manifest</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span>
<span class="p">)</span>
<span class="n">manifest</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;YEAR&#39;</span><span class="p">)[</span><span class="s1">&#39;NAME&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                                                  <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Number of Stories per Year&quot;</span><span class="p">,</span>
                                                  <span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;Year&quot;</span><span class="p">,</span>
                                                  <span class="n">ylabel</span> <span class="o">=</span> <span class="s2">&quot;Count&quot;</span><span class="p">,</span>
                                                  <span class="n">yticks</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
                                                 <span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of stories: 50 
Number of authors: 50 
Columns in the manifest: [&#39;NAME&#39; &#39;YEAR&#39; &#39;FILE_NAME&#39;]
</pre></div>
</div>
<img alt="_images/04_corpus-analytics_2_1.png" src="_images/04_corpus-analytics_2_1.png" />
</div>
</div>
<p>Here are a few story titles, selected at random:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">title</span> <span class="ow">in</span> <span class="n">manifest</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">manifest</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">title</span><span class="p">,</span> <span class="s1">&#39;NAME&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NELSON, Antonya: FemaleTrouble
OATES, JOYCECAROL: TheTranslation
LINK, Kelly: Stone Animals
EISENBERG, Deborah: TwilightoftheSuperheroes
YARBROUGH, Steve: TheRestofHerLife
</pre></div>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Using a metadata sheet like this is a good habit to develop. Use it as a common reference point for any processes
you run on your data, and you’ll mitigate major headaches stemming from undocumented projects. For more about this,
see the DataLab’s <a class="reference external" href="https://ucdavisdatalab.github.io/workshop_how-to-data-documentation/">workshop on project organization and data documentation</a>.</p>
</div>
</div>
<div class="section" id="text-cleaning">
<h2><span class="section-number">4.2. </span>Text Cleaning<a class="headerlink" href="#text-cleaning" title="Permalink to this headline">¶</a></h2>
<div class="section" id="recap">
<h3><span class="section-number">4.2.1. </span>Recap<a class="headerlink" href="#recap" title="Permalink to this headline">¶</a></h3>
<p>With our manifest loaded, we can review our cleaning steps. For each short story in our corpus, we want to:</p>
<ol class="simple">
<li><p>Resolve casing</p></li>
<li><p>Remove punctuation, numbers, and any extra formatting</p></li>
<li><p>Remove stop words</p></li>
</ol>
<p>This should feel familiar, though our workflow here will differ slightly from the one in the last chapter because
we’ll be cleaning multiple texts, not only one. All the principles remain the same, we just want to implement our
cleaning steps in a way that successively works through every text in our data directory without much intervention
on our part. This is where functions are helpful; we’ll define a series of them, with each performing a separate
step in the cleaning process. We’ll also define a main function, <code class="docutils literal notranslate"><span class="pre">clean()</span></code>, which we’ll use to control the various
cleaning steps. That way we can simply load in a text file and pass it to <code class="docutils literal notranslate"><span class="pre">clean()</span></code> and <code class="docutils literal notranslate"><span class="pre">clean()</span></code> will handle the
rest.</p>
<p>Note that our steps do not include lemmatizing the texts. Because lemmatization can be labor- and time-intensive,
<strong>these texts have already been processed with <code class="docutils literal notranslate"><span class="pre">nltk</span></code>’s lemmatizer</strong>.</p>
</div>
<div class="section" id="text-cleaning-functions">
<h3><span class="section-number">4.2.2. </span>Text cleaning functions<a class="headerlink" href="#text-cleaning-functions" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">clean()</span></code> will call the following five functions:</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">to_lower()</span></code>: returns a lowercase version of all tokens in a text</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">remove_punctuation()</span></code>: removes all punctuation in phases: hyphens, em dashes, and underscores first, then
everything else</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">remove_digits()</span></code>: removes digits</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">remove_whitespace()</span></code>: removes any extra whitespace</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">remove_stop_words()</span></code>: filters out stop words from the list of tokens; we’ll also remove any words that are two
or less characters long</p></li>
</ol>
<p>Let’s get coding!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/voyant_stoplist.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">stopwords</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">to_lower</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">remove_punctuation</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[-]|[—]|[_]&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^\w\s]&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">doc</span>

<span class="k">def</span> <span class="nf">remove_digits</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[0-9]&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">remove_whitespace</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\s+&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">doc</span>

<span class="k">def</span> <span class="nf">remove_stop_words</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">doc</span>

<span class="k">def</span> <span class="nf">clean</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="n">lowercase</span> <span class="o">=</span> <span class="n">to_lower</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">no_punct</span> <span class="o">=</span> <span class="n">remove_punctuation</span><span class="p">(</span><span class="n">lowercase</span><span class="p">)</span>
    <span class="n">no_digits</span> <span class="o">=</span> <span class="n">remove_digits</span><span class="p">(</span><span class="n">no_punct</span><span class="p">)</span>
    <span class="n">no_whitespace</span> <span class="o">=</span> <span class="n">remove_whitespace</span><span class="p">(</span><span class="n">no_digits</span><span class="p">)</span>
    <span class="n">stopped</span> <span class="o">=</span> <span class="n">remove_stop_words</span><span class="p">(</span><span class="n">no_whitespace</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">stopped</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-about-the-above admonition">
<p class="admonition-title">About the above…</p>
<p>These functions are written with <strong>clarity</strong> and <strong>modularity</strong> in mind. The intent here is to demonstrate each
step of the cleaning process in as discrete a manner as possible. But you might find that some of this code is
redundant (as an example, ask yourself: which step might be wrapped up inside another function?). Further, we could
very probably re-factor this code to optimize it, which would be important when working with a large number of
texts. We won’t cover something like that in this session, however. For now, know that these functions are meant to
act as templates, which you can modify to suit your own needs.</p>
</div>
</div>
<div class="section" id="cleaning-our-texts">
<h3><span class="section-number">4.2.3. </span>Cleaning our texts<a class="headerlink" href="#cleaning-our-texts" title="Permalink to this headline">¶</a></h3>
<p>With our functions defined, we can now load each story, roll through all the cleaning steps, and append the cleaned
story to a list. The result will be our <strong>corpus</strong>, a fifty-item list of strings, where each string contains all
the tokens in a given story. The <em>order</em> of these entries will be important for work we want to do later on, so we
need to make sure that each string always has the same position in the larger list of stories. This is where the
file manifest comes in: <em>we’ll load stories in the order provided by the <code class="docutils literal notranslate"><span class="pre">FILE_NAME</span></code> column of <code class="docutils literal notranslate"><span class="pre">manifest</span></code></em>. Doing
so ensures that the first index (<code class="docutils literal notranslate"><span class="pre">0</span></code>) of our corpus corresponds to the first short story, the second index (<code class="docutils literal notranslate"><span class="pre">1</span></code>) to
the second, and so on.</p>
<p>Let’s write all this out in a <code class="docutils literal notranslate"><span class="pre">for</span></code> loop and do our cleaning.</p>
<div class="margin sidebar">
<p class="sidebar-title">What this loop does:</p>
<ol class="simple">
<li><p>For every row (<code class="docutils literal notranslate"><span class="pre">idx</span></code>) in <code class="docutils literal notranslate"><span class="pre">manifest</span></code>, collect the item in the row’s <code class="docutils literal notranslate"><span class="pre">FILE_NAME</span></code> column and append it to <code class="docutils literal notranslate"><span class="pre">indir</span></code></p></li>
<li><p>Put the resultant filepath in a <code class="docutils literal notranslate"><span class="pre">with...open</span></code> statement to read in a file</p></li>
<li><p>Clean the story with <code class="docutils literal notranslate"><span class="pre">clean()</span></code></p></li>
<li><p>Append the result to <code class="docutils literal notranslate"><span class="pre">corpus</span></code></p></li>
</ol>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">indir</span> <span class="o">=</span>  <span class="s2">&quot;data/session_two/input/&quot;</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">title</span> <span class="ow">in</span> <span class="n">manifest</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">indir</span> <span class="o">+</span> <span class="n">manifest</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">title</span><span class="p">,</span> <span class="s1">&#39;FILE_NAME&#39;</span><span class="p">]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">story</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">cleaned_story</span> <span class="o">=</span> <span class="n">clean</span><span class="p">(</span><span class="n">story</span><span class="p">)</span>
        <span class="n">corpus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cleaned_story</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As a sanity check, we can run an assertion statement, which checks that <code class="docutils literal notranslate"><span class="pre">corpus</span></code> has as many stories in it as
<code class="docutils literal notranslate"><span class="pre">manifest</span></code> does…</p>
<div class="margin sidebar">
<p class="sidebar-title">On assertions…</p>
<p>If the lengths of <code class="docutils literal notranslate"><span class="pre">corpus</span></code> and <code class="docutils literal notranslate"><span class="pre">manifest</span></code> didn’t match, <code class="docutils literal notranslate"><span class="pre">assert</span></code> would throw an <code class="docutils literal notranslate"><span class="pre">AssertionError</span></code> with the message
after the comma.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">manifest</span><span class="p">),</span> <span class="s2">&quot;Lengths don&#39;t match!&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>…and we can inspect some tokens from a few stories to make sure all is well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">39</span><span class="p">]:</span>
    <span class="n">fragment</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">fragment</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>behind card table outside food minute sun shift chair table
barbie away ken practice future sit sisters room watch barbie
silver cloud float horizon robin sparrow trees son joshuas seventh
</pre></div>
</div>
</div>
</div>
<p>Looks great!</p>
</div>
</div>
<div class="section" id="the-document-term-matrix">
<h2><span class="section-number">4.3. </span>The Document-Term Matrix<a class="headerlink" href="#the-document-term-matrix" title="Permalink to this headline">¶</a></h2>
<p>Before we switch into full data exploration mode, we’re going to perform one last formatting process on our corpus.
Remember from the last chapter that much of text analytics relies on <strong>counts</strong> and <strong>context</strong>: tracking the
former in tandem with the latter is how we identify relationships between words (the final section on bigram PMI
scores demonstrated this, for example). As with <em>Frankenstein</em>, here we’ll want to tally up all the words in each
story. That produces one kind of context – or rather, fifty different contexts: one for every story. But we have at
our hands a corpus, the analysis of which requires a different kind of context: a single one for all the stories.
That is, we need a way to relate stories <em>to each other</em>, instead of only tracking word values inside a single
text.</p>
<p>To do so, we’ll build a <strong>document-term matrix</strong>, or <strong>DTM</strong>. A DTM is a matrix that contains the frequencies of
<em>all</em> terms in a corpus. Every row in this matrix corresponds to a document, while every column corresponds to a
term. For a given document, we count the number of times that term appears and enter that number in the column in
question. We do this <em>even if</em> the count is zero; key to the way a DTM works is that it represents corpus-wide
relationships between texts, so it matters if a text does or doesn’t contain a term.</p>
<p>Here’s a toy example. Imagine three documents:</p>
<ol class="simple">
<li><p>“I like cats. Do you?”</p></li>
<li><p>“I only like dogs. And you?”</p></li>
<li><p>“I like cats and dogs.”</p></li>
</ol>
<p>Transforming these into a document-term matrix would yield:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_corpus</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>

<span class="n">example_dtm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">example_corpus</span><span class="p">,</span> 
                           <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;D1&#39;</span><span class="p">,</span> <span class="s1">&#39;D2&#39;</span><span class="p">,</span> <span class="s1">&#39;D3&#39;</span><span class="p">],</span> 
                           <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;only&#39;</span><span class="p">,</span> <span class="s1">&#39;like&#39;</span><span class="p">,</span> <span class="s1">&#39;cats&#39;</span><span class="p">,</span> <span class="s1">&#39;and&#39;</span><span class="p">,</span> <span class="s1">&#39;dogs&#39;</span><span class="p">,</span> <span class="s1">&#39;do&#39;</span><span class="p">,</span> <span class="s1">&#39;you&#39;</span><span class="p">]</span>
                          <span class="p">)</span>

<span class="n">example_dtm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>i</th>
      <th>only</th>
      <th>like</th>
      <th>cats</th>
      <th>and</th>
      <th>dogs</th>
      <th>do</th>
      <th>you</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D1</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>D2</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>D3</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Representing texts in this way is incredibly useful because it enables us to easily (and programmatically) discern
similarities and differences in our corpus. For example, we can see that each of the above documents contains the
words “I” and “like.” Given that, if we wanted to know what makes each document unique, we could ignore those two
words and focus on the rest of the values.</p>
<p>Now, imagine doing this for thousands of words. What patterns might emerge?</p>
<p>The <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> library makes generating a DTM very easy. All we need to do is import a <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code>
object, initialize it by assigning it to a variable, and fit it to our corpus. This will result in two things: 1) a
fitted <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code>, which will contain a series of different attributes that are useful for corpus
exploration; 2) a vectorized representation of our corpus, the document-term matrix.</p>
<div class="margin sidebar">
<p class="sidebar-title">More on this</p>
<p><code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> accepts several different arguments that will modify its base functionality, including
arguments for applying some text cleaning steps. We won’t use any of these arguments because we’ve already cleaned
our text (and indeed it’s a good idea to clean your text yourself so you always know what processes have been run
on it), but you can learn more about them <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">here</a>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">vectorized_corpus</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Shape of our document-term matrix: </span><span class="si">{</span><span class="n">vectorized_corpus</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,&quot;</span><span class="p">,</span> 
    <span class="sa">f</span><span class="s2">&quot;or </span><span class="si">{</span><span class="n">vectorized_corpus</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> documents (rows)&quot;</span><span class="p">,</span> 
    <span class="sa">f</span><span class="s2">&quot;and </span><span class="si">{</span><span class="n">vectorized_corpus</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> words (columns)&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of our document-term matrix: (50, 15962), or 50 documents (rows) and 15962 words (columns)
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> returns a <strong>sparse matrix</strong>, or a matrix comprised mostly of zeros. This matrix has been
formatted to be highly memory efficient, which is useful when dealing with giant datasets, but it’s not very
accessible for data exploration. Since our corpus is relatively small, we’ll convert this sparse matrix into a
<code class="docutils literal notranslate"><span class="pre">Pandas</span></code> dataframe. Note all the zeros!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vectorized_corpus</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="n">dtm</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">,:</span><span class="mi">15</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>As it stands, this dataframe is hard to understand. But luckily, we’ve kept track of which row corresponds to which
story: this is why we used our manifest to control our file order. Further, the fitted <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> has a
special method, <code class="docutils literal notranslate"><span class="pre">get_feature_names_out()</span></code>, which will generate an array of all the tokens from all the files (our
vocabulary). The order of this array corresponds to the order of our columns. Accordingly, we can assign this array
to the column names of <code class="docutils literal notranslate"><span class="pre">dtm</span></code> and assign the story titles in <code class="docutils literal notranslate"><span class="pre">manifest</span></code> to its index names, making it much easier to
associate column values with row values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtm</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
<span class="n">dtm</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">manifest</span><span class="o">.</span><span class="n">index</span>
<span class="n">dtm</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">,:</span><span class="mi">15</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aaa</th>
      <th>aaaaargh</th>
      <th>aaaargh</th>
      <th>aachen</th>
      <th>aachens</th>
      <th>aahed</th>
      <th>aback</th>
      <th>abandon</th>
      <th>abandoned</th>
      <th>abbey</th>
      <th>abbreviate</th>
      <th>abby</th>
      <th>abbylucyferny</th>
      <th>abdomen</th>
      <th>abdominal</th>
    </tr>
    <tr>
      <th>TITLE</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>TheSchool</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Tony’sStory</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>NineteenFifty-five</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Girl</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Territory</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="analyzing-the-corpus">
<h2><span class="section-number">4.4. </span>Analyzing the Corpus<a class="headerlink" href="#analyzing-the-corpus" title="Permalink to this headline">¶</a></h2>
<p>With our DTM made, we can use it to generate some metrics about each text in our corpus. We’ll use <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> data
manipulations in conjunction with <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> to do this.</p>
<div class="section" id="raw-metrics-documents">
<h3><span class="section-number">4.4.1. </span>Raw Metrics: Documents<a class="headerlink" href="#raw-metrics-documents" title="Permalink to this headline">¶</a></h3>
<p>Here’s an easy one: let’s count the number of tokens in each story and assign the result to a new column in our
manifest.</p>
<div class="margin sidebar">
<p class="sidebar-title">Vectorized functions</p>
<p>If you’re unfamiliar with <code class="docutils literal notranslate"><span class="pre">apply()</span></code>, or it’s just been a while since you’ve used it, this method applies a function
along an axis of a dataframe. Think of it like a shorthand for a <code class="docutils literal notranslate"><span class="pre">for</span></code> loop: the default usage runs every column
through your desired function. In this case, we’re setting the <code class="docutils literal notranslate"><span class="pre">axis</span></code> to <code class="docutils literal notranslate"><span class="pre">1</span></code> so <code class="docutils literal notranslate"><span class="pre">sum()</span></code> runs on every row. This
will sum together each value in every row.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">manifest</span> <span class="o">=</span> <span class="n">manifest</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">NUM_TOKENS</span> <span class="o">=</span> <span class="n">dtm</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">sum</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;NUM_TOKENS&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                                                               <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Tokens per Story&quot;</span><span class="p">,</span>
                                                               <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;Title&#39;</span><span class="p">,</span>
                                                               <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;Number of Tokens&#39;</span>
                                                              <span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/04_corpus-analytics_27_0.png" src="_images/04_corpus-analytics_27_0.png" />
</div>
</div>
<p>We can also count the number of unique words, or <strong>types</strong>, in each story. Types correspond to a story’s
vocabulary, whereas tokens correspond to the amount of each type in a story.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">manifest</span> <span class="o">=</span> <span class="n">manifest</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">NUM_TYPES</span> <span class="o">=</span> <span class="n">dtm</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;NUM_TYPES&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                                                              <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Types per Story&quot;</span><span class="p">,</span>
                                                              <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;Title&#39;</span><span class="p">,</span>
                                                              <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;Number of Types&#39;</span>
                                                             <span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/04_corpus-analytics_29_0.png" src="_images/04_corpus-analytics_29_0.png" />
</div>
</div>
<p>With tokens and types generated, we can generate a measure of <strong>lexical diversity</strong>. There are a few such measures.
We’ll go with a <strong>type-token ratio</strong> (TTR), which measures how much the vocabulary of a text varies over its
tokens. It’s a simple metric: divide the number of types (unique words) by the total number of tokens in a text and
normalize the result. A text with a TTR of 100, for example, would never repeat a word.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">manifest</span> <span class="o">=</span> <span class="n">manifest</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">TTR</span> <span class="o">=</span> <span class="p">(</span><span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;NUM_TYPES&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;NUM_TOKENS&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;TTR&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                                                        <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Type–Token Ratios per Story&#39;</span><span class="p">,</span>
                                                        <span class="n">legend</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                                                        <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;Title&#39;</span><span class="p">,</span>
                                                        <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;Type–Token Ratio %&#39;</span><span class="p">,</span>
                                                        <span class="n">yticks</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
                                                       <span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/04_corpus-analytics_31_0.png" src="_images/04_corpus-analytics_31_0.png" />
</div>
</div>
<p>With this, we can make some preliminary comparisons across our corpus, weighing the vocabulary of one story against
another.</p>
</div>
<div class="section" id="raw-metrics-terms">
<h3><span class="section-number">4.4.2. </span>Raw Metrics: Terms<a class="headerlink" href="#raw-metrics-terms" title="Permalink to this headline">¶</a></h3>
<p>Let’s move to terms. Here are the top five most frequent terms in the corpus:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>say     2028
like    1495
know    1031
look     953
said     867
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>And here are the bottom five:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>aaa              1
heartbroken      1
heartbreaking    1
heartbreak       1
heartache        1
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Though there are likely to be quite a few one-count terms. Here are the bottom ten:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>aaa              1
heartbroken      1
heartbreaking    1
heartbreak       1
heartache        1
hearse           1
hears            1
signature        1
significance     1
significant      1
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Each of these terms is called a <strong>hapax legomenon</strong> (Greek for “only said once”). How many are in our corpus
altogether?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hapaxes</span> <span class="o">=</span> <span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()[</span><span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Number of hapax legomenons: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">hapaxes</span><span class="p">)</span><span class="si">}</span><span class="s2">,&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot;or </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">hapaxes</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dtm</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="si">:</span><span class="s2">.02f</span><span class="si">}</span><span class="s2">% of the words in our corpus&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of hapax legomenons: 7463, or 0.47% of the words in our corpus
</pre></div>
</div>
</div>
</div>
<p>How many terms are in the top five quantiles of the term counts?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">count_quantile</span> <span class="o">=</span> <span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.95</span><span class="p">)</span>
<span class="n">count_quantile_words</span> <span class="o">=</span> <span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()[</span><span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">count_quantile</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Word counts for the ninety-fifth quantile: </span><span class="si">{</span><span class="n">count_quantile</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Number of words with counts at or above this quantile: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">count_quantile_words</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> 
    <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">count_quantile_words</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dtm</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="si">:</span><span class="s2">.02f</span><span class="si">}</span><span class="s2">% of words)&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Word counts for the ninety-fifth quantile: 31.0 
Number of words with counts at or above this quantile: 801 (0.05% of words)
</pre></div>
</div>
</div>
</div>
<p>The discrepancies between the above two values should feel familiar: our term distribution is Zipfian.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Term Counts&#39;</span><span class="p">,</span>
                                            <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;Term&#39;</span><span class="p">,</span> 
                                            <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;Count&#39;</span><span class="p">,</span>
                                            <span class="n">xticks</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dtm</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="mi">750</span><span class="p">),</span>
                                            <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span>
                                           <span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/04_corpus-analytics_44_0.png" src="_images/04_corpus-analytics_44_0.png" />
</div>
</div>
<p>This distribution has a few consequences for us. It suggests, for example, that we might have some more cleaning
to do in terms of stop word removal: “say” and “like” could be candidates for removal. If we don’t remove these
terms, we might have trouble identifying unique aspects of each story in our corpus. Highly frequent terms will
choke out differences across the corpus, as we can see here with the top terms for each story:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtm</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TITLE
TheSchool                                   say
Tony’sStory                                leon
NineteenFifty-five                          say
Girl                                       dont
Territory                                  neil
HowFarSheWent                              girl
SarahColeATypeofLoveStory                   say
Caviar                                    marie
WinnersonthePassLine                        ray
TheWayWeLiveNow                             say
Communist                                  glen
TheManagementofGrief                        say
TheFireman’sWife                           says
Wickedness                                  say
Lust                                       like
TwoKinds                                 mother
TheDisappeared                             said
ARealDoll                                barbie
TheThingsTheyCarried                      carry
NeverMarryaMexican                         like
CarCrashWhileHitchhiking                    car
Marie                                     marie
TheKindofLightThatShinesonTexas             say
SilverWater                                rose
ThePugilistatRest                          like
TheTranslation                           oliver
Orientation                                 sit
JealousHusbandReturnsinFormofParrot         say
Relief                                 bromhead
AfterRosaParks                            ellie
Tiny, Smiling Daddy                       kitty
Xmas,JamaicaPlain                           say
TheRestofHerLife                            say
Nilda                                       say
ATemporaryMatter                          shoba
TheHalf-SkinnedSteer                        say
SeaOak                                      say
Boys                                      house
TheCavemenintheHedges                       kim
TheHermit&#39;sStory                         joshua
TheCeiling                                  dog
TheCaretaker                             joseph
Pilgrims                                   ella
Brownies                                    say
WeDidn’t                                  night
TheSecretGoldfish                          fish
MyShape                                    like
Stone Animals                              said
FemaleTrouble                           mcbride
TwilightoftheSuperheroes                 lucien
dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top_terms</span> <span class="o">=</span> <span class="n">dtm</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;say&#39;</span><span class="p">,</span> <span class="s1">&#39;says&#39;</span><span class="p">,</span> <span class="s1">&#39;said&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Stories where </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> is the top word: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">top_terms</span><span class="p">[</span><span class="n">top_terms</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">target</span><span class="p">)])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Stories where [&#39;say&#39;, &#39;says&#39;, &#39;said&#39;] is the top word: 17
</pre></div>
</div>
</div>
</div>
<p>That’s a third of our stories!</p>
<p>But there’s also an argument to be made for keeping “said” and “say” in our corpus. We are, after all, looking at
narrative stories, and it matters that there’s dialogue. Removing these words would prevent us from studying this
later on.</p>
<p>How, then, can we have it both ways? How can we reduce the influence of highly frequent terms without removing them
altogether?</p>
</div>
<div class="section" id="weighted-metrics-tf-idf-scores">
<h3><span class="section-number">4.4.3. </span>Weighted Metrics: tf-idf Scores<a class="headerlink" href="#weighted-metrics-tf-idf-scores" title="Permalink to this headline">¶</a></h3>
<p>The answer is to <strong>weight</strong> our terms, doing so in a way that lessens the impact of terms we know to be highly
general in our corpus and that increases the impact of unique terms for each story. The most popular way to do this
is to implement <strong>tf-idf, or term frequency–inverse document frequency, scoring</strong>. In essence, a tf-idf score is a
measure of term specificity in the context of a given document. It is the product of a term’s frequency in that
document and the number of documents in which that term appears. By offsetting terms that appear across many
documents, tf-idf pushes down the scores of common terms and boosts the scores of rarer ones.</p>
<div class="margin sidebar">
<p class="sidebar-title">The idf score</p>
<p>We calculate the inverse document frequency (idf) score with</p>
<p><span class="math notranslate nohighlight">\(idf_i = log(\frac{n}{df_i})\)</span></p>
<p>Where <span class="math notranslate nohighlight">\(idf_i\)</span>, the idf score for term <span class="math notranslate nohighlight">\(i\)</span>, is the log of <span class="math notranslate nohighlight">\(n\)</span>, the total number of documents, over <span class="math notranslate nohighlight">\(df_i\)</span>, the
number of documents that contain <span class="math notranslate nohighlight">\(i\)</span>.</p>
</div>
<p>A tf-idf score can be expressed as</p>
<p><span class="math notranslate nohighlight">\(w_i,_j = tf_i,_j \cdot idf_i\)</span></p>
<p>Where, for term <span class="math notranslate nohighlight">\(i\)</span> and document <span class="math notranslate nohighlight">\(j\)</span>, the score <span class="math notranslate nohighlight">\(w\)</span> is the term frequency, or <span class="math notranslate nohighlight">\(tf_i,_j\)</span>, for <span class="math notranslate nohighlight">\(i\)</span> in <span class="math notranslate nohighlight">\(j\)</span>, multiplied
by <span class="math notranslate nohighlight">\(idf_i\)</span>, the inverse document score. The higher the score, the more specific a term is for a given document.</p>
<p>Conveniently, we don’t need to implement any of this math ourselves. <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> has a <code class="docutils literal notranslate"><span class="pre">TfidfVectorizer()</span></code>
object, which works just like <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code>, but instead of producing a DTM of raw term counts, it produces a
DTM of tf-idf scores. Let’s import <code class="docutils literal notranslate"><span class="pre">TfidfVectorizer()</span></code>, initialize it, fit it to our corpus, and generate a new DTM
with these scores.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="n">vectorized_with_tfidf</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="n">tfidf_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vectorized_with_tfidf</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
                            <span class="n">index</span> <span class="o">=</span> <span class="n">manifest</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                            <span class="n">columns</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
                           <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf_scores</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">,:</span><span class="mi">15</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aaa</th>
      <th>aaaaargh</th>
      <th>aaaargh</th>
      <th>aachen</th>
      <th>aachens</th>
      <th>aahed</th>
      <th>aback</th>
      <th>abandon</th>
      <th>abandoned</th>
      <th>abbey</th>
      <th>abbreviate</th>
      <th>abby</th>
      <th>abbylucyferny</th>
      <th>abdomen</th>
      <th>abdominal</th>
    </tr>
    <tr>
      <th>TITLE</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>TheSchool</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Tony’sStory</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>NineteenFifty-five</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Girl</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Territory</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.007863</td>
      <td>0.070767</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>To see the difference tf-idf scores make, let’s look at the top terms for each story according to these scores,
rather than raw counts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf_scores</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TITLE
TheSchool                                  helen
Tony’sStory                                 leon
NineteenFifty-five                       traynor
Girl                                        dont
Territory                                   neil
HowFarSheWent                             granny
SarahColeATypeofLoveStory                  sarah
Caviar                                     marie
WinnersonthePassLine                         ray
TheWayWeLiveNow                          quentin
Communist                                   glen
TheManagementofGrief                       kusum
TheFireman’sWife                            jane
Wickedness                                hattie
Lust                                        like
TwoKinds                                   piano
TheDisappeared                            anders
ARealDoll                                 barbie
TheThingsTheyCarried                       carry
NeverMarryaMexican                          like
CarCrashWhileHitchhiking                     car
Marie                                      marie
TheKindofLightThatShinesonTexas           oakley
SilverWater                                 rose
ThePugilistatRest                       jorgeson
TheTranslation                            oliver
Orientation                              cubicle
JealousHusbandReturnsinFormofParrot         bird
Relief                                  bromhead
AfterRosaParks                             ellie
Tiny, Smiling Daddy                        kitty
Xmas,JamaicaPlain                          emile
TheRestofHerLife                         chuckie
Nilda                                       rafa
ATemporaryMatter                           shoba
TheHalf-SkinnedSteer                       rollo
SeaOak                                       min
Boys                                        boys
TheCavemenintheHedges                        kim
TheHermit&#39;sStory                          joshua
TheCeiling                                   ann
TheCaretaker                              joseph
Pilgrims                                    ella
Brownies                                 arnetta
WeDidn’t                                   drown
TheSecretGoldfish                           fish
MyShape                                   pierre
Stone Animals                          catherine
FemaleTrouble                            mcbride
TwilightoftheSuperheroes                  lucien
dtype: object
</pre></div>
</div>
</div>
</div>
<p>Note all the names, which have fully replaced those common words from before. This makes intuitive sense: most
stories are about specific characters, and these characters’ names tend not to occur in other stories. Given that
tf-idf scores help us home in on term specificity, they’re going to highlight this fact.</p>
<p>Let’s also look at a single story. We’ll compare the top ten raw counts for that story and the top ten tf-idf
scores.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top ten term counts for The Things They Carried</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">story</span> <span class="o">=</span> <span class="s1">&#39;TheThingsTheyCarried&#39;</span>
<span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">dtm</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">story</span><span class="p">]</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">term</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">dtm</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">story</span><span class="p">,</span> <span class="n">term</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top ten term counts for The Things They Carried

     carry: 114
      love: 28
lieutenant: 27
     cross: 26
       say: 25
     pound: 23
  lavender: 22
    martha: 21
      just: 20
       men: 19
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top ten tf-idf scores for The Things They Carried</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">tfidf_scores</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">story</span><span class="p">]</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">term</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">tfidf_scores</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">story</span><span class="p">,</span> <span class="n">term</span><span class="p">]</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top ten tf-idf scores for The Things They Carried

     carry: 0.4399
lieutenant: 0.2567
    martha: 0.2304
  lavender: 0.2092
     kiowa: 0.1820
   sanders: 0.1456
       ted: 0.1426
     jimmy: 0.1421
     pound: 0.1344
     weigh: 0.1282
</pre></div>
</div>
</div>
</div>
<p>Note how, in the above, common words like “say” and “just” slip out of the tf-idf rankings, to be replaced instead
by names and other nouns.</p>
<p>If we wanted to get a sense of just how specific each of these terms are to our story, we can compare them with
that term’s mean score in the corpus.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_tfidf</span> <span class="o">=</span> <span class="n">tfidf_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">tfidf_scores</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">story</span><span class="p">]</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">term</span><span class="p">,</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">+ Text tf-idf: </span><span class="si">{</span><span class="n">tfidf_scores</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">story</span><span class="p">,</span> <span class="n">term</span><span class="p">]</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">+ Mean tf-idf: </span><span class="si">{</span><span class="n">mean_tfidf</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">term</span><span class="p">]</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>carry 
+ Text tf-idf: 0.4399 
+ Mean tf-idf: 0.0159

lieutenant 
+ Text tf-idf: 0.2567 
+ Mean tf-idf: 0.0083

martha 
+ Text tf-idf: 0.2304 
+ Mean tf-idf: 0.0128

lavender 
+ Text tf-idf: 0.2092 
+ Mean tf-idf: 0.0048

kiowa 
+ Text tf-idf: 0.1820 
+ Mean tf-idf: 0.0036

sanders 
+ Text tf-idf: 0.1456 
+ Mean tf-idf: 0.0029

ted 
+ Text tf-idf: 0.1426 
+ Mean tf-idf: 0.0037

jimmy 
+ Text tf-idf: 0.1421 
+ Mean tf-idf: 0.0032

pound 
+ Text tf-idf: 0.1344 
+ Mean tf-idf: 0.0070

weigh 
+ Text tf-idf: 0.1282 
+ Mean tf-idf: 0.0031
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="term-correlations">
<h3><span class="section-number">4.4.4. </span>Term Correlations<a class="headerlink" href="#term-correlations" title="Permalink to this headline">¶</a></h3>
<p>Looking beyond a single story, we can use our tf-idf DTM to identify correlations across the corpus. These
correlations aren’t a perfect stand-in for semantic similarity, but they will give us a sense of how two terms are
associated among the documents, much in the way a PMI score indicated the specificity of bigrams in the last
chapter. Let’s grab five random terms from our corpus (the columns of <code class="docutils literal notranslate"><span class="pre">tfidf_scores</span></code>) and calculate correlations
between them with the <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> <code class="docutils literal notranslate"><span class="pre">corr()</span></code> function.</p>
<div class="margin sidebar">
<p class="sidebar-title">Note:</p>
<p>We’re stacking these numbers together for ease of reading, but the raw output of <code class="docutils literal notranslate"><span class="pre">corr()</span></code> is a correlation matrix.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_five</span> <span class="o">=</span> <span class="n">tfidf_scores</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tfidf_scores</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="mi">5</span><span class="p">)]</span>
<span class="n">tfidf_scores</span><span class="p">[</span><span class="n">random_five</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>winnie       winnie         1.000000
             decapitated   -0.020408
             fellowship    -0.031614
             sew           -0.023550
             exist         -0.069954
decapitated  winnie        -0.020408
             decapitated    1.000000
             fellowship    -0.031614
             sew           -0.023550
             exist         -0.069954
fellowship   winnie        -0.031614
             decapitated   -0.031614
             fellowship     1.000000
             sew           -0.036480
             exist         -0.108363
sew          winnie        -0.023550
             decapitated   -0.023550
             fellowship    -0.036480
             sew            1.000000
             exist         -0.064974
exist        winnie        -0.069954
             decapitated   -0.069954
             fellowship    -0.108363
             sew           -0.064974
             exist          1.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can also select terms ourselves and see how they correlate:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">selected_terms</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;book&#39;</span><span class="p">:</span> <span class="s1">&#39;page&#39;</span><span class="p">,</span> <span class="s1">&#39;yell&#39;</span><span class="p">:</span> <span class="s1">&#39;whisper&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="s1">&#39;zucchini&#39;</span><span class="p">}</span>

<span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">selected_terms</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Correlation between </span><span class="si">{</span><span class="n">term</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">selected_terms</span><span class="p">[</span><span class="n">term</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">,</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tfidf_scores</span><span class="p">[</span><span class="n">term</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">tfidf_scores</span><span class="p">[</span><span class="n">selected_terms</span><span class="p">[</span><span class="n">term</span><span class="p">]])</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlation between book and page    : 0.5978
Correlation between yell and whisper : 0.1631
Correlation between mean and zucchini: -0.1580
</pre></div>
</div>
</div>
</div>
<p>With these metrics in hand, there’s much to explore in our corpus. But what we haven’t yet done so far is merge the
two levels of our investigations. That is, we’ve explored our corpus at the level of documents, and we’ve explored
our corpus at the level of terms, but what we haven’t yet done is use one to explore the other. The next chapter
will take this up in full. We’ll be using our tf-idf DTM to do so, so let’s save it. We’ll also be using our fitted
<code class="docutils literal notranslate"><span class="pre">TfidfVectorizer()</span></code>, for reasons that the next chapter will explain. For now, let’s save that too and end here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="n">outdir</span> <span class="o">=</span> <span class="s2">&quot;data/session_two/output/&quot;</span>

<span class="n">tfidf_scores</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">outdir</span> <span class="o">+</span> <span class="s2">&quot;tfidf_scores.csv&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">outdir</span> <span class="o">+</span> <span class="s2">&quot;tfidf_vectorizer.pkl&quot;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">tfidf_vectorizer</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "nlp"
        },
        kernelOptions: {
            kernelName: "nlp",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'nlp'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="03_cleaning-and-counting.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">3. </span>Cleaning and Counting</p>
            </div>
        </a>
    </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Tyler Shoemaker and Carl Stahmer<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>