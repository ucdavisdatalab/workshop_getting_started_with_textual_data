{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f29d934",
   "metadata": {},
   "source": [
    "Before We Begin...\n",
    "===============\n",
    "\n",
    "This reader is meant to serve both as a roadmap for the overall trajectory of the series and as a reference for \n",
    "later work you may do in text mining. Our sessions will follow its overall logic, but the reader itself offers \n",
    "substantially more details than we may have time to discuss in the sessions. The instructors will call attention to \n",
    "this when appropriate; you are encouraged to consult the reader whenever you would like to learn more about a \n",
    "particular topic.\n",
    "\n",
    "Each session of this workshop will cover material from one or more chapters. We also ask that you **read Chapter 2 \n",
    "in advance of our first session**. It's a review of sorts and will set up a frame for the series.\n",
    "\n",
    "| Session | Date | Chapters Covered | Topic                                    |\n",
    "| ------- | ---- | ---------------- | ---------------------------------------- |\n",
    "|    0*   |  --  |     Chapter 2    | Review: textual data in Python           |\n",
    "|    1    | 2/18 |     Chapter 3    | Text cleaning                            |\n",
    "|    2    | 2/20 |  Chapters 4 & 5  | Corpus analytics and document clustering |\n",
    "|    3    | 2/22 |     Chapter 6    | Topic modeling                           |\n",
    "\n",
    "\\* Please read in advance\n",
    "\n",
    "```{admonition} Learning Objectives\n",
    "By the end of this series, you will be able to:\n",
    "\n",
    "+ Prepare textual data for analysis using a variety of cleaning processes\n",
    "+ Recognize and explain how these cleaning processes impact research findings\n",
    "+ Explain key terminology in text mining, including \"tokenization,\" \"n-grams,\" \"lexical diversity,\" and more\n",
    "+ Use special data structures (such as document-term matrices) to efficiently analyze multiple texts\n",
    "+ Use statistical measures (pointwise mutual information, tf-idf) to identify significant patterns in text\n",
    "+ Cluster and classify texts on the basis of such measures\n",
    "+ Produce statistical models of \"toics\" from/about a collection of texts\n",
    "```\n",
    "\n",
    "File and Data Setup\n",
    "-----------------------\n",
    "\n",
    "We will be using Google Colab's during the series... TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71be0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
